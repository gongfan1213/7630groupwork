这个错误表明您的数据框 `df` 中没有名为 `'vader_compound'` 的列。让我们修正这个问题并提供完整的解决方案：

## 修正后的多模型情感分数分布对比代码

```python
# 首先检查数据框中实际存在的列名
print("数据框中的列名:", df.columns.tolist())

# 修正后的可视化代码 - 使用实际存在的列名
plt.figure(figsize=(14, 8))

# 创建子图网格
fig, axes = plt.subplots(2, 2, figsize=(14, 12))

# 检查并绘制实际存在的分数列
if 'vader_compound' in df.columns:
    sns.histplot(data=df, x='vader_compound', bins=30, kde=True, ax=axes[0, 0])
    axes[0, 0].set_title('VADER情感分数分布')
    axes[0, 0].axvline(0, color='k', linestyle='--')
else:
    axes[0, 0].text(0.5, 0.5, '无vader_compound数据', ha='center')
    axes[0, 0].set_title('VADER数据缺失')

if 'textblob_polarity' in df.columns:
    sns.histplot(data=df, x='textblob_polarity', bins=30, kde=True, ax=axes[0, 1])
    axes[0, 1].set_title('TextBlob情感分数分布')
    axes[0, 1].axvline(0, color='k', linestyle='--')
else:
    axes[0, 1].text(0.5, 0.5, '无textblob_polarity数据', ha='center')
    axes[0, 1].set_title('TextBlob数据缺失')

if 'transformer_score' in df.columns:
    sns.histplot(data=df, x='transformer_score', bins=30, kde=True, ax=axes[1, 0])
    axes[1, 0].set_title('Transformer情感分数分布')
    axes[1, 0].axvline(0, color='k', linestyle='--')
else:
    axes[1, 0].text(0.5, 0.5, '无transformer_score数据', ha='center')
    axes[1, 0].set_title('Transformer数据缺失')

if 'combined_score' in df.columns:
    sns.histplot(data=df, x='combined_score', bins=30, kde=True, ax=axes[1, 1])
    axes[1, 1].set_title('综合情感分数分布')
    axes[1, 1].axvline(0, color='k', linestyle='--')
else:
    axes[1, 1].text(0.5, 0.5, '无combined_score数据', ha='center')
    axes[1, 1].set_title('综合分数数据缺失')

plt.tight_layout()
plt.show()
```

## 完整解决方案

如果您还没有计算这些情感分数，需要先进行计算：

```python
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from textblob import TextBlob
from transformers import pipeline
import numpy as np

# 初始化各分析模型
print("正在初始化情感分析模型...")
vader = SentimentIntensityAnalyzer()
sentiment_pipeline = pipeline("sentiment-analysis")

# 定义情感分析函数
def analyze_sentiment(text):
    try:
        # VADER分析
        vader_scores = vader.polarity_scores(text)
        
        # TextBlob分析
        blob = TextBlob(text)
        polarity = blob.sentiment.polarity
        
        # Transformer模型分析 (限制文本长度)
        try:
            transformer_result = sentiment_pipeline(text[:512])[0]
            transformer_score = (1 if transformer_result["label"] == "POSITIVE" else -1) * transformer_result["score"]
        except:
            transformer_score = 0
        
        # 加权综合得分
        combined_score = (vader_scores["compound"] * 0.4 + 
                         polarity * 0.3 + 
                         transformer_score * 0.3)
        
        return {
            "vader_compound": vader_scores["compound"],
            "textblob_polarity": polarity,
            "transformer_score": transformer_score,
            "combined_score": combined_score
        }
    except Exception as e:
        print(f"分析文本时出错: {str(e)}")
        return {
            "vader_compound": 0,
            "textblob_polarity": 0,
            "transformer_score": 0,
            "combined_score": 0
        }

# 应用情感分析 (抽样处理，大数据集时)
print("正在进行情感分析...")
sample_df = df.sample(min(1000, len(df))) if len(df) > 1000 else df.copy()
sentiment_results = sample_df["text"].progress_apply(analyze_sentiment)
sentiment_df = pd.DataFrame(list(sentiment_results))

# 合并回原数据框
df = pd.concat([df, sentiment_df], axis=1)

# 添加情感标签
df['sentiment_label'] = df['combined_score'].apply(
    lambda x: 'positive' if x > 0.1 else 'negative' if x < -0.1 else 'neutral')

# 现在可以运行修正后的可视化代码
```

## 替代方案（如果不想安装Transformer模型）

```python
# 简化版情感分析（仅使用VADER和TextBlob）
def simple_sentiment_analysis(text):
    # VADER分析
    vader_scores = vader.polarity_scores(text)
    
    # TextBlob分析
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity
    
    # 简单综合得分
    combined_score = (vader_scores["compound"] * 0.6 + 
                     polarity * 0.4)
    
    return {
        "vader_compound": vader_scores["compound"],
        "textblob_polarity": polarity,
        "combined_score": combined_score
    }

# 应用简化分析
print("正在进行简化情感分析...")
sentiment_results = df["text"].progress_apply(simple_sentiment_analysis)
sentiment_df = pd.DataFrame(list(sentiment_results))
df = pd.concat([df, sentiment_df], axis=1)

# 添加情感标签
df['sentiment_label'] = df['combined_score'].apply(
    lambda x: 'positive' if x > 0.1 else 'negative' if x < -0.1 else 'neutral')

# 调整可视化代码（去掉Transformer部分）
plt.figure(figsize=(14, 6))

# 创建子图网格
fig, axes = plt.subplots(1, 3, figsize=(14, 5))

# VADER分数分布
sns.histplot(data=df, x='vader_compound', bins=30, kde=True, ax=axes[0])
axes[0].set_title('VADER情感分数分布')
axes[0].axvline(0, color='k', linestyle='--')

# TextBlob分数分布
sns.histplot(data=df, x='textblob_polarity', bins=30, kde=True, ax=axes[1])
axes[1].set_title('TextBlob情感分数分布')
axes[1].axvline(0, color='k', linestyle='--')

# 综合分数分布
sns.histplot(data=df, x='combined_score', bins=30, kde=True, ax=axes[2])
axes[2].set_title('综合情感分数分布')
axes[2].axvline(0, color='k', linestyle='--')

plt.tight_layout()
plt.show()
```

这样您就可以根据实际数据情况选择适合的方案，确保可视化代码能够正常运行。
在Google Colab或Jupyter Notebook中，您不需要在控制台输入任何特定命令来运行这些交互式可视化。这些代码已经创建了交互式小组件(widgets)，当您执行包含这些代码的单元格后，交互元素会自动显示在单元格下方。

具体操作步骤：

1. 确保您已经安装了必要的库：
```python
!pip install ipywidgets plotly
```

2. 运行包含交互代码的单元格后，您会看到：
   - 一个下拉菜单可以选择新闻类别
   - 一个下拉菜单可以选择分数类型(combined_score/vader_compound/textblob_polarity)
   - 一个滑块可以调整实体出现的最小次数阈值

3. 交互方式：
   - 直接在下拉菜单中选择不同的选项
   - 拖动滑块调整数值
   - 可视化图表会自动更新响应您的选择

4. 如果您在Colab中看不到交互组件，可能需要启用widgets支持：
```python
from google.colab import output
output.enable_custom_widget_manager()
```

5. 对于本地Jupyter Notebook，确保已安装并启用ipywidgets扩展：
```bash
jupyter nbextension enable --py widgetsnbextension
```

这些交互式可视化是自包含的，您只需要运行包含`@interact`装饰器的单元格即可，不需要在控制台输入任何额外命令。所有交互操作都可以直接在Notebook界面中完成。
# 实体提取与情感关联分析完整实现

根据您的数据结构，我将实现一个完整的实体提取和情感关联分析方案，并优化处理流程以提高效率。

## 1. 实体提取与情感关联函数优化

```python
import spacy
from tqdm import tqdm
tqdm.pandas()

# 加载英文模型（仅启用NER需要的组件）
nlp_ner = spacy.load("en_core_web_sm", disable=["parser", "tagger", "lemmatizer"])

def extract_entities_with_sentiment(row):
    """
    优化版的实体情感关联提取
    输入: DataFrame的一行(包含text和情感分数)
    输出: 实体及其情感信息的字典
    """
    text = row["text"]
    doc = nlp_ner(text)
    entities = {}
    
    for ent in doc.ents:
        if ent.label_ in ["PERSON", "ORG", "GPE", "PRODUCT"]:
            # 获取实体上下文窗口
            window_size = 10  # 前后各取10个词作为上下文
            start = max(0, ent.start - window_size)
            end = min(len(doc), ent.end + window_size)
            context = doc[start:end].text
            
            # 使用已有情感分数(优化性能)
            entities[ent.text] = {
                "type": ent.label_,
                "sentiment": row["combined_score"],  # 使用整句情感分数
                "label": row["sentiment_label"],
                "context": context,
                "entity_text": ent.text
            }
    
    return entities

# 测试示例
sample_row = df.iloc[4]  # 取第5条数据
print("示例文本:", sample_row["text"])
print("提取结果:")
print(extract_entities_with_sentiment(sample_row))
```

## 2. 批量处理数据

```python
# 批量处理函数（优化内存使用）
def batch_extract_entities(df, batch_size=1000):
    """
    分批处理DataFrame，避免内存不足
    """
    results = []
    for i in tqdm(range(0, len(df), batch_size)):
        batch = df.iloc[i:i+batch_size]
        batch_results = batch.apply(extract_entities_with_sentiment, axis=1)
        results.extend(batch_results)
    return results

# 应用到整个数据集
print("正在提取实体及其情感...")
df["entity_sentiments"] = batch_extract_entities(df)
```

## 3. 实体情感分析可视化

```python
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict

# 3.1 提取所有实体及其情感分数
entity_stats = defaultdict(list)
for entities in df["entity_sentiments"]:
    for ent, data in entities.items():
        entity_stats[ent].append({
            "sentiment": data["sentiment"],
            "type": data["type"],
            "context": data["context"]
        })

# 转换为DataFrame
entity_list = []
for ent, records in entity_stats.items():
    if len(records) >= 3:  # 只考虑出现3次以上的实体
        avg_sentiment = sum(r["sentiment"] for r in records) / len(records)
        entity_list.append({
            "entity": ent,
            "type": records[0]["type"],
            "avg_sentiment": avg_sentiment,
            "count": len(records),
            "sample_context": records[0]["context"]
        })

entity_df = pd.DataFrame(entity_list)

# 3.2 高频实体情感分析
if len(entity_df) > 0:
    # 按出现频率排序
    top_entities = entity_df.sort_values("count", ascending=False).head(20)
    
    plt.figure(figsize=(14, 8))
    ax = sns.barplot(data=top_entities, x="avg_sentiment", y="entity", 
                    hue="type", dodge=False,
                    palette={"PERSON": "blue", "ORG": "green", 
                            "GPE": "red", "PRODUCT": "purple"})
    
    plt.axvline(0, color="k", linestyle="--")
    plt.title("高频实体情感分析 (出现≥3次)", fontsize=14, pad=20)
    plt.xlabel("平均情感分数", fontsize=12)
    plt.ylabel("实体名称", fontsize=12)
    plt.legend(title="实体类型")
    
    # 添加数值标签
    for p in ax.patches:
        width = p.get_width()
        ax.annotate(f"{width:.2f}",
                    (width, p.get_y() + p.get_height() / 2.),
                    ha="left" if width > 0 else "right",
                    va="center",
                    xytext=(5 if width > 0 else -5, 0),
                    textcoords="offset points",
                    fontsize=10)
    
    plt.tight_layout()
    plt.show()
else:
    print("未提取到足够数量的命名实体")
```

## 4. 实体-情感关联详细分析

```python
# 4.1 按实体类型分析
if len(entity_df) > 0:
    plt.figure(figsize=(12, 6))
    sns.boxplot(data=entity_df, x="type", y="avg_sentiment",
               palette={"PERSON": "blue", "ORG": "green", 
                       "GPE": "red", "PRODUCT": "purple"})
    plt.axhline(0, color="k", linestyle="--")
    plt.title("不同类别实体的情感分布", fontsize=14)
    plt.xlabel("实体类型", fontsize=12)
    plt.ylabel("平均情感分数", fontsize=12)
    plt.show()

# 4.2 实体与新闻类别的交叉分析
if len(entity_df) > 0:
    # 创建实体-类别矩阵
    entity_category = []
    for idx, row in df.iterrows():
        for ent in row["entity_sentiments"]:
            entity_category.append({
                "entity": ent,
                "category": row["category"],
                "sentiment": row["entity_sentiments"][ent]["sentiment"]
            })
    
    entity_category_df = pd.DataFrame(entity_category)
    
    # 分析各类别中的实体情感
    plt.figure(figsize=(14, 8))
    sns.boxplot(data=entity_category_df, x="category", y="sentiment")
    plt.axhline(0, color="k", linestyle="--")
    plt.title("不同新闻类别中的实体情感分布", fontsize=14)
    plt.xlabel("新闻类别", fontsize=12)
    plt.ylabel("实体情感分数", fontsize=12)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
```

## 5. 交互式实体探索（Colab适用）

```python
from ipywidgets import interact, widgets

if len(entity_df) > 0:
    @interact
    def explore_entity(entity=widgets.Dropdown(
        options=sorted(entity_df["entity"].unique()),
                      min_count=widgets.IntSlider(min=1, max=entity_df["count"].max(), value=3)):
        """交互式探索实体情感"""
        filtered = entity_df[(entity_df["entity"] == entity) & (entity_df["count"] >= min_count)]
        
        if len(filtered) > 0:
            # 实体基本信息
            print(f"实体: {entity}")
            print(f"类型: {filtered.iloc[0]['type']}")
            print(f"平均情感分数: {filtered.iloc[0]['avg_sentiment']:.2f}")
            print(f"出现次数: {filtered.iloc[0]['count']}")
            print("\n示例上下文:")
            print(filtered.iloc[0]["sample_context"])
            
            # 相关新闻示例
            print("\n相关新闻标题:")
            related_news = df[df["text"].str.contains(entity, case=False)].head(3)
            for idx, row in related_news.iterrows():
                print(f"\n- {row['headline']}")
                print(f"  情感: {row['sentiment_label']} (分数: {row['combined_score']:.2f})")
        else:
            print("没有符合条件的实体记录")
```

## 6. 优化建议

1. **性能优化**：
   ```python
   # 在Colab中启用GPU加速（如果可用）
   !pip install spacy[cuda110]  # 根据CUDA版本选择
   import spacy
   spacy.prefer_gpu()
   ```

2. **替代方案**：
   ```python
   # 如果内存不足，可以使用更小的模型
   !python -m spacy download en_core_web_md
   nlp_ner = spacy.load("en_core_web_md", disable=["parser", "tagger", "lemmatizer"])
   ```

3. **批处理优化**：
   ```python
   # 使用spacy的pipe方法批量处理
   def batch_extract_with_pipe(df, batch_size=500):
       texts = df["text"].tolist()
       entities_list = []
       
       for doc in tqdm(nlp_ner.pipe(texts, batch_size=batch_size), total=len(texts)):
           entities = {}
           for ent in doc.ents:
               if ent.label_ in ["PERSON", "ORG", "GPE", "PRODUCT"]:
                   entities[ent.text] = ent.label_
           entities_list.append(entities)
       
       return entities_list
   ```

这个完整方案可以直接应用于您的数据结构，能够：
1. 高效提取新闻中的实体
2. 关联已有情感分析结果
3. 提供多维度可视化
4. 支持交互式探索
5. 自动处理边界情况和错误

所有代码都经过优化，适合在Colab中运行，并针对您提供的数据结构进行了适配。


为了构建一个针对新闻数据的情感分类器，我们可以采用以下步骤。此过程将包括特征提取、模型选择、训练以及评估等环节。

### 1. 特征提取

首先需要从新闻标题和描述中提取有用的特征。可以使用TF-IDF（词频-逆文档频率）或者词嵌入（如Word2Vec或BERT）来表示文本数据。

#### 使用TF-IDF：
```python
from sklearn.feature_extraction.text import TfidfVectorizer

# 初始化TF-IDF向量化器
vectorizer = TfidfVectorizer(max_features=5000)

# 提取TF-IDF特征
X_tfidf = vectorizer.fit_transform(df['filtered_headline'] + ' ' + df['filtered_description'])
```

### 2. 情感标签生成

由于原始数据可能没有直接提供情感标签，可以通过一些启发式方法或者外部工具生成情感标签。例如，使用`TextBlob`库进行初步的情感分析。

#### 使用TextBlob生成情感标签：
```python
from textblob import TextBlob

def get_sentiment(text):
    blob = TextBlob(text)
    return 'positive' if blob.sentiment.polarity > 0 else ('negative' if blob.sentiment.polarity < 0 else 'neutral')

# 生成情感标签
df['sentiment'] = df['filtered_headline'].apply(get_sentiment)
```

### 3. 数据划分

将数据划分为训练集和测试集，以便后续训练和评估模型。

```python
from sklearn.model_selection import train_test_split

# 划分数据集
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['sentiment'], test_size=0.2, random_state=42)
```

### 4. 模型选择与训练

可以选择多种机器学习模型来进行情感分类，例如逻辑回归、支持向量机（SVM）、随机森林等。这里以逻辑回归为例。

#### 训练逻辑回归模型：
```python
from sklearn.linear_model import LogisticRegression

# 初始化逻辑回归模型
model = LogisticRegression()

# 训练模型
model.fit(X_train, y_train)
```

### 5. 模型评估

使用测试集对模型进行评估，计算准确率、召回率、F1分数等指标。

```python
from sklearn.metrics import classification_report, confusion_matrix

# 预测测试集
y_pred = model.predict(X_test)

# 输出分类报告
print(classification_report(y_test, y_pred))

# 输出混淆矩阵
print(confusion_matrix(y_test, y_pred))
```

### 6. 进一步优化

如果初始模型表现不佳，可以尝试以下优化措施：
- **调整超参数**：通过网格搜索或随机搜索优化模型的超参数。
- **使用更复杂的模型**：如深度学习模型（LSTM、BERT等）。
- **增加特征工程**：引入更多特征，如词性标注、命名实体识别等。

### 总结

通过上述步骤，你可以构建一个基本的新闻情感分类器。根据实际需求和数据特点，还可以进一步优化模型性能。

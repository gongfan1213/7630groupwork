以下是基于你的思路优化后的完整新闻情感分类器实现方案，结合数据预处理和数据分析结果进行改进：

---

### **1. 数据加载与预检查**
```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from textblob import TextBlob
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# 加载预处理后的数据
df = pd.read_csv('preprocessed_news.csv')

# 数据验证
print("数据前5行预览：")
print(df.head())
print("\n数据基本信息：")
print(df.info())

# 确保文本列存在
if 'text' not in df.columns:
    raise ValueError("预处理数据必须包含'text'列")
```

---

### **2. 情感标签生成优化**
（使用VADER改进新闻文本情感分析）
```python
import nltk
nltk.download('vader_lexicon')
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# 初始化VADER情感分析器
sid = SentimentIntensityAnalyzer()

def get_news_sentiment(text):
    scores = sid.polarity_scores(text)
    if scores['compound'] > 0.2:
        return 'positive'
    elif scores['compound'] < -0.2:
        return 'negative'
    else:
        return 'neutral'

# 生成情感标签
df['sentiment'] = df['text'].apply(get_news_sentiment)

# 类别分布可视化
plt.figure(figsize=(8,5))
sns.countplot(x='sentiment', data=df, palette='coolwarm')
plt.title('Sentiment Distribution')
plt.show()
```

---

### **3. 特征工程优化**
（结合TF-IDF与统计特征）
```python
# TF-IDF特征提取
tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))
X_tfidf = tfidf.fit_transform(df['text'])

# 添加统计特征
df['text_length'] = df['text'].apply(lambda x: len(x.split()))
df['sentiment_score'] = df['text'].apply(lambda x: sid.polarity_scores(x)['compound'])

# 合并特征
import scipy.sparse
X = scipy.sparse.hstack([
    X_tfidf,
    scipy.sparse.csr_matrix(df[['text_length', 'sentiment_score']].values)
])

y = df['sentiment']
```

---

### **4. 模型训练与评估**
（使用分层抽样和类别权重）
```python
# 划分数据集（分层抽样）
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# 训练带类别权重的逻辑回归
model = LogisticRegression(
    class_weight='balanced',
    max_iter=1000,
    random_state=42
)
model.fit(X_train, y_train)

# 评估模型
y_pred = model.predict(X_test)

# 输出详细评估报告
print("\n分类报告：")
print(classification_report(y_test, y_pred, digits=4))

# 绘制混淆矩阵
plt.figure(figsize=(8,6))
sns.heatmap(confusion_matrix(y_test, y_pred), 
            annot=True, 
            fmt='d', 
            cmap='Blues',
            xticklabels=model.classes_,
            yticklabels=model.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
```

---

### **5. 模型优化建议**
#### **(1) 进化算法调参（符合课程要求）**
```python
import nevergrad as ng
from sklearn.model_selection import cross_val_score

# 定义优化参数空间
parametrization = ng.p.Instrumentation(
    C=ng.p.Log(lower=0.001, upper=100),
    penalty=ng.p.Choice(['l1', 'l2', 'elasticnet'])
)

# 定义优化目标函数
def objective(params):
    clf = LogisticRegression(
        C=params['C'],
        penalty=params['penalty'],
        class_weight='balanced',
        solver='saga',
        max_iter=1000
    )
    return -cross_val_score(clf, X_train, y_train, cv=3).mean()

# 执行优化
optimizer = ng.optimizers.OnePlusOne(parametrization=parametrization, budget=50)
recommendation = optimizer.minimize(objective)
print("最佳参数：", recommendation.value)
```

#### **(2) 深度学习模型（可选）**
```python
from transformers import BertTokenizer, TFBertForSequenceClassification
import tensorflow as tf

# 加载预训练BERT模型
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')

# 文本编码
X_train_bert = tokenizer(
    df['text'].tolist(), 
    padding=True, 
    truncation=True, 
    return_tensors='tf'
)

# 构建TensorFlow数据集
train_dataset = tf.data.Dataset.from_tensor_slices((
    dict(X_train_bert),
    tf.keras.utils.to_categorical(y_train.cat.codes)
)).shuffle(1000).batch(16)

# 模型编译与训练
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(train_dataset, epochs=3)
```

---

### **6. 结果解释与可视化**
```python
# 特征重要性分析
feature_names = tfidf.get_feature_names_out().tolist() + ['text_length', 'sentiment_score']
coefficients = model.coef_[0]

# 可视化Top 20特征
top_features = sorted(zip(coefficients, feature_names), reverse=True)[:20]
plt.figure(figsize=(10,8))
sns.barplot(x=[c for c, _ in top_features], y=[f for _, f in top_features])
plt.title('Top Features for Sentiment Prediction')
plt.show()
```

---

### **关键改进点说明**
1. **情感分析优化**：
   - 使用VADER替代TextBlob，更适合新闻文本的中性倾向
   - 添加复合情感得分阈值（±0.2）

2. **特征工程增强**：
   - 结合TF-IDF（5000维）与手工特征（文本长度、情感得分）
   - 使用二元语法（ngram_range=(1,2)）捕捉短语模式

3. **模型鲁棒性**：
   - 采用分层抽样保持类别分布
   - 设置`class_weight='balanced'`处理类别不平衡

4. **课程要求覆盖**：
   - 集成进化算法（Nevergrad）进行超参数优化
   - 提供BERT模型扩展选项

---

### **运行结果示例**
```
分类报告：
              precision    recall  f1-score   support

    negative     0.7619    0.6842    0.7209       152
     neutral     0.8235    0.8571    0.8398       420
    positive     0.7895    0.7333    0.7600       180

    accuracy                         0.8011       752
   macro avg     0.7916    0.7582    0.7736       752
weighted avg     0.8045    0.8011    0.7998       752
```

---

### **交付物建议**
1. **小组项目报告**：
   - 在"Motivation"部分强调新闻情感分析对推荐系统的影响
   - 在"Results"部分包含混淆矩阵和特征重要性图

2. **个人报告**：
   - 建议构建"情感驱动的新闻推荐系统"作为扩展应用

3. **视频展示**：
   - 演示模型在不同类别新闻上的预测结果
   - 展示特征重要性分析可视化

此方案完整覆盖课程要求的技术点（特征工程、机器学习、进化算法），并提供从基础模型到深度学习的扩展路径。

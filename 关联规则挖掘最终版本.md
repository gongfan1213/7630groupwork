在完成情感分析后，我们可以使用关联规则挖掘（Association Rule Mining）来发现不同情感类别与文本特征（如实体、关键词、类别等）之间的有趣关联。以下是完整的实现方案：

### 1. 数据预处理（准备关联规则挖掘）

```python
import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules

# 准备关联规则挖掘所需的数据
def prepare_association_data(df):
    """
    准备关联规则挖掘的数据集
    返回:
        - 处理后的交易数据集 (用于apriori算法)
        - 原始DataFrame的扩展版本 (包含one-hot编码特征)
    """
    # 确保必要的列存在
    if 'sentiment_label' not in df.columns:
        print("请先运行情感分析!")
        return None, None
    
    # 1. 提取每行文本的特征
    transactions = []
    for _, row in df.iterrows():
        features = []
        
        # 添加情感标签
        features.append(f"sentiment={row['sentiment_label']}")
        
        # 添加新闻类别 (如果存在)
        if 'category' in df.columns:
            features.append(f"category={row['category']}")
        
        # 添加入选实体 (如果存在)
        if 'entity_sentiments' in df.columns and isinstance(row['entity_sentiments'], dict):
            for entity in row['entity_sentiments'].keys():
                features.append(f"entity={entity}")
        
        # 添加高频关键词 (从sentiment_text提取)
        if 'sentiment_text' in df.columns:
            top_words = [word for word in str(row['sentiment_text']).split() 
                        if len(word) > 3][:5]  # 取长度>3的前5个词
            for word in top_words:
                features.append(f"word={word.lower()}")
        
        transactions.append(features)
    
    # 2. 转换为one-hot编码格式
    te = TransactionEncoder()
    te_ary = te.fit(transactions).transform(transactions)
    trans_df = pd.DataFrame(te_ary, columns=te.columns_)
    
    return transactions, trans_df

# 准备数据
transactions, trans_df = prepare_association_data(df)
print(f"生成 {len(trans_df.columns)} 个特征:")
print(trans_df.columns.tolist()[:10])  # 显示前10个特征
```

### 2. 关联规则挖掘实现

```python
def mine_association_rules(trans_df, min_support=0.05, min_threshold=0.5):
    """
    执行关联规则挖掘
    参数:
        trans_df: one-hot编码的交易数据
        min_support: 最小支持度
        min_threshold: 最小提升度阈值
    """
    # 1. 找出频繁项集
    frequent_itemsets = apriori(trans_df, min_support=min_support, use_colnames=True)
    print(f"\n找到 {len(frequent_itemsets)} 个频繁项集 (min_support={min_support})")
    
    if len(frequent_itemsets) == 0:
        print("没有找到频繁项集，请降低min_support阈值")
        return None
    
    # 2. 生成关联规则
    rules = association_rules(frequent_itemsets, metric="lift", min_threshold=min_threshold)
    print(f"生成 {len(rules)} 条关联规则 (min_threshold={min_threshold})")
    
    if len(rules) == 0:
        print("没有生成关联规则，请降低min_threshold阈值")
        return None
    
    # 3. 过滤并排序规则
    interesting_rules = rules[
        (rules['consequents'].apply(lambda x: any('sentiment=' in item for item in x))) &
        (rules['lift'] > 1)
    ].sort_values(['lift', 'confidence'], ascending=False)
    
    return interesting_rules

# 执行关联规则挖掘
rules = mine_association_rules(trans_df, min_support=0.03, min_threshold=0.7)

# 显示最有意义的规则
if rules is not None and len(rules) > 0:
    pd.set_option('display.max_colwidth', 100)
    print("\nTop 10 有趣关联规则:")
    display(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10))
else:
    print("\n没有发现有趣的关联规则")
```

### 3. 关联规则可视化与分析

```python
import networkx as nx
import matplotlib.pyplot as plt

def visualize_rules(rules, top_n=10):
    """可视化关联规则网络图"""
    if rules is None or len(rules) == 0:
        print("没有可可视化的规则")
        return
    
    # 准备数据
    top_rules = rules.head(top_n)
    graph = nx.DiGraph()
    
    # 添加节点和边
    for _, row in top_rules.iterrows():
        antecedents = ', '.join(list(row['antecedents']))
        consequents = ', '.join(list(row['consequents']))
        weight = row['lift']
        
        graph.add_edge(antecedents, consequents, weight=weight)
    
    # 绘制网络图
    plt.figure(figsize=(12, 8))
    pos = nx.spring_layout(graph, k=0.5)
    
    # 节点大小基于度数
    node_sizes = [3000 * graph.degree(node) for node in graph.nodes()]
    
    # 边宽度基于lift值
    edge_widths = [2 * row['weight'] for _, _, row in graph.edges(data=True)]
    
    # 绘制
    nx.draw_networkx_nodes(graph, pos, node_size=node_sizes, alpha=0.7,
                          node_color='skyblue')
    nx.draw_networkx_edges(graph, pos, width=edge_widths, alpha=0.5,
                          edge_color='gray', arrowsize=20)
    nx.draw_networkx_labels(graph, pos, font_size=10, font_weight='bold')
    
    # 添加标题和说明
    plt.title(f"Top {top_n} 情感关联规则 (边宽度表示lift值)", fontsize=14)
    plt.axis('off')
    
    # 添加图例
    plt.text(0.5, -0.1, 
             "箭头方向: 前提 → 结果\n节点大小: 连接数量\n边宽度: 规则lift值",
             ha='center', transform=plt.gca().transAxes)
    
    plt.tight_layout()
    plt.show()

# 可视化规则
visualize_rules(rules)

# 分析特定情感类别的规则
if rules is not None:
    for sentiment in ['positive', 'negative', 'neutral']:
        sent_rules = rules[rules['consequents'].apply(
            lambda x: f"sentiment={sentiment}" in x)]
        
        if len(sent_rules) > 0:
            print(f"\n与'{sentiment}'情感相关的规则:")
            display(sent_rules[['antecedents', 'consequents', 
                              'support', 'confidence', 'lift']].head(5))
```

### 4. 完整执行流程

```python
# 1. 数据准备
print("步骤1: 准备关联规则挖掘数据...")
transactions, trans_df = prepare_association_data(df)

# 2. 挖掘关联规则
print("\n步骤2: 挖掘关联规则...")
rules = mine_association_rules(trans_df, 
                              min_support=0.03, 
                              min_threshold=0.7)

# 3. 可视化与分析
if rules is not None and len(rules) > 0:
    print("\n步骤3: 可视化与分析...")
    visualize_rules(rules)
    
    # 保存结果
    rules.to_csv("sentiment_association_rules.csv", index=False)
    print("\n关联规则已保存到 sentiment_association_rules.csv")
else:
    print("\n没有发现显著的关联规则")
```

### 关键改进点：

1. **自动化特征工程**：
   - 自动从文本中提取实体、关键词等特征
   - 将情感标签作为目标变量

2. **智能参数调整**：
   - 自动建议参数调整方向（当没有找到规则时）
   - 提供默认参数但允许灵活调整

3. **多维度分析**：
   - 同时考虑实体、类别、关键词等多个维度
   - 支持分析不同情感类别的特有模式

4. **交互式可视化**：
   - 网络图清晰展示规则间关系
   - 视觉编码（大小、宽度）表示规则重要性

5. **业务解释性**：
   - 规则格式易于业务理解（如 "entity=Apple => sentiment=positive"）
   - 提供统计显著性指标（lift值）

### 典型输出示例：

```
Top 10 有趣关联规则:
                           antecedents               consequents   support  confidence  lift
0  (category=TECH, word=iphone)       (sentiment=positive)       0.082     0.85      2.1
1  (entity=Apple, word=new)            (sentiment=positive)       0.071     0.82      2.0
2  (category=POLITICS, word=trump)    (sentiment=negative)       0.065     0.78      2.3
...
``` 

这个实现可以帮助您发现诸如：
- "科技类新闻中提及iPhone与积极情感高度相关"
- "政治新闻中提及Trump常伴随负面情感" 
等有价值的业务洞察。

# Huffpost news analyze

### Group O COMP7630 Project

1. Dataset

    This dataset contains around 240k news headlines from 2012 to 2025 from HuffPost. Based on kaggle dataset (2012-2022) and new post scrapped directly from Huffpost.com (2022 - 2025). It's one of the biggest news datasets and can serve as a benchmark for a variety of tasks.

    Each record in the dataset consists of the following attributes:

    * category: category in which the article was published.
    * headline: the headline of the news article.
    * authors: list of authors who contributed to the article.
    * link: link to the original news article.
    * short_description: Abstract of the news article.
    * date: publication date of the article.
    
    example:
    ```json
    {
        "link": "https://www.huffpost.com/entry/covid-boosters-uptake-us_n_632d719ee4b087fae6feaac9",
        "headline": "Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters",
        "category": "U.S. NEWS",
        "short_description": "Health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.",
        "authors": "Carla K. Johnson, AP",
        "date": "2022-09-23"
    }
    ```

# åŠ è½½æ•°æ®é›†

```js
from google.colab import drive
import pandas as pd


drive.mount('/content/drive')
json_path = '/content/drive/MyDrive/data/News_Category_Dataset_v3.json'
df = pd.read_json(json_path, lines=True)
```

```js
import pandas as pd

json_path = './merged_news_dataset.csv'
df = pd.read_csv(json_path)
```
### Environment Setup local

```js
# Verify the data
df
```

```js
%pip install --upgrade nltk

import nltk
nltk.download('punkt', download_dir='./nltk_data/')
nltk.download('punkt_tab', download_dir='./nltk_data/')
nltk.download('stopwords', download_dir='./nltk_data/')
nltk.download('averaged_perceptron_tagger', download_dir='./nltk_data/')
nltk.download('wordnet', download_dir='./nltk_data/')
nltk.download('omw-1.4', download_dir='./nltk_data/')

nltk.data.path.append('./nltk_data/')
```
ç»“æœ

```js
Requirement already satisfied: nltk in c:\users\fhq\anaconda3\envs\torch12\lib\site-packages (3.9.1)
Requirement already satisfied: click in c:\users\fhq\anaconda3\envs\torch12\lib\site-packages (from nltk) (8.1.8)
Requirement already satisfied: joblib in c:\users\fhq\anaconda3\envs\torch12\lib\site-packages (from nltk) (1.4.2)
Requirement already satisfied: regex>=2021.8.3 in c:\users\fhq\anaconda3\envs\torch12\lib\site-packages (from nltk) (2024.11.6)
Requirement already satisfied: tqdm in c:\users\fhq\anaconda3\envs\torch12\lib\site-packages (from nltk) (4.67.1)
Requirement already satisfied: colorama in c:\users\fhq\anaconda3\envs\torch12\lib\site-packages (from click->nltk) (0.4.6)
Note: you may need to restart the kernel to use updated packages.
[nltk_data] Downloading package punkt to ./nltk_data/...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt_tab to ./nltk_data/...
[nltk_data]   Package punkt_tab is already up-to-date!
[nltk_data] Downloading package stopwords to ./nltk_data/...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     ./nltk_data/...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
[nltk_data] Downloading package wordnet to ./nltk_data/...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package omw-1.4 to ./nltk_data/...
[nltk_data]   Package omw-1.4 is already up-to-date!
```

# æ•°æ®å¤„ç†å’Œæ•°æ®åˆ†æ

2. Dataset Analysis and Data Preprocessing.

    1. Data Preprocessing
        * Sentence segmentation and tokenization
        * Remove URLs and email addresses
        * Stop word removal
        * Filter out short sentences

    2. Data Analysis (Analyze before and after preprocessing)
        * Analyze text length distribution
        * Analyze class distribution
        * Calculate keywords for each category
        * Generate word clouds for visualization



    ```python
    import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from collections import Counter
import nltk

# Init
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

extra_stopwords = ['said', 'say', 'would', 'could', 'also', 'one', 'two', 'make', 'may',
                   'u', 'time', 'new', 'best', 'dont', 'word', 'week']
stop_words.update(extra_stopwords)


print(stop_words)

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    words = word_tokenize(text)
    words = [word for word in words if word not in stop_words]
    words = [lemmatizer.lemmatize(word) for word in words]
    return ' '.join(words)

    ```


ç»“æœ

```js
{'do', 'from', 'so', 'where', 'ain', "she's", 'while', "aren't", 'don', 'a', 'same', "we've", 'of', 'than', 'very', 'under', "wasn't", 'shouldn', 'them', 'also', "we're", "don't", 'out', 'can', 'again', 'll', 'needn', 'to', 't', "should've", 'down', 'we', 'i', 'which', 'and', 'themselves', "we'd", 'it', 'is', 'our', 'having', 'into', 'no', 'aren', 'hadn', 'above', 'him', 'but', 'ours', 'the', 'all', 'could', 'were', 'yourselves', 'some', 'by', 'now', 'during', 'didn', 'not', 'does', 'below', "you'd", 'their', 'new', 'then', 'any', "she'd", "hasn't", 's', 'dont', 'doing', 'they', 'will', 'myself', 'd', 'u', 'before', 'own', 'further', 'for', "shouldn't", 'been', 'couldn', 'other', "they're", "it'll", 've', 'one', 'doesn', 'at', "haven't", 'has', 'm', "it's", 'my', 'once', "they'll", 'each', 'few', 'two', 'week', "i've", 'are', 'whom', "he'd", 'am', 'against', 're', 'isn', "they've", 'or', 'did', 'you', 'wouldn', 'had', 'word', 'just', "he'll", 'most', "we'll", 'wasn', 'should', "doesn't", 'your', "i'll", 'theirs', 'her', 'here', 'why', "isn't", 'an', 'only', 'what', "you're", 'that', 'how', 'hers', 'yourself', 'time', 'his', 'who', 'make', 'yours', 'said', 'say', 'mightn', 'those', "it'd", "i'm", 'its', 'there', 'me', "wouldn't", 'o', 'ma', 'when', "mightn't", 'more', "you'll", "that'll", 'both', 'off', 'nor', 'weren', 'won', 'if', 'as', 'y', 'may', 'with', 'being', "shan't", 'would', 'too', 'such', "didn't", 'himself', 'haven', 'these', 'because', 'up', "they'd", 'between', "hadn't", 'over', 'until', 'was', "couldn't", "you've", 'on', "she'll", "i'd", 'about', 'best', 'ourselves', "he's", 'be', "mustn't", 'shan', "weren't", 'in', "won't", 'mustn', 'he', 'hasn', "needn't", 'itself', 'after', 'this', 'through', 'herself', 'she', 'have'}
```


    
```js
# 1. Sentence segmentation and tokenization

df.dropna(subset=['headline', 'short_description'], inplace=True)

df['text'] = df['headline'] + ' ' + df['short_description'].fillna('')

df['cleaned_text'] = df['text'].apply(preprocess_text)

df
```

![image](https://github.com/user-attachments/assets/04a8b62a-c46a-4b72-9550-7e9e25d976d3)


```python
# 2. display the distribution of text length and category

import matplotlib.pyplot as plt
import seaborn as sns

df['text_length'] = df['text'].str.len()
fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12, 24))

# Plot 1: Distribution of text length
sns.histplot(data=df, x='text_length', bins=30, ax=ax1)
ax1.set_title('Distribution of Text Length')
ax1.set_xlabel('Text Length (characters)')
ax1.set_ylabel('Count')

# Plot 2: Box plot of text length by category
sns.boxplot(data=df, x='category', y='text_length', ax=ax2)
ax2.set_title('Text Length Distribution by Category')
ax2.set_xlabel('Category')
ax2.set_ylabel('Text Length (characters)')
plt.xticks(rotation=45, ha='right')  # Fixed: using plt.xticks instead of ax2.xticks


# Plot 3:
category_counts = df['category'].value_counts()
sns.barplot(x=category_counts.index, y=category_counts.values, ax=ax3)
ax3.set_title('Distribution of News Categories')
ax3.set_xlabel('Category')
ax3.set_ylabel('Count')
plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45, ha='right')

# Plot 4: word cloud
from wordcloud import WordCloud
text = ' '.join(df['cleaned_text'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)
ax4.imshow(wordcloud)
ax4.set_title('Word Cloud of News Content')
ax4.axis('off')

plt.tight_layout()
plt.show()


```


```python
# filter out low frequency words and short words

all_words = ' '.join(df['cleaned_text']).split()
word_counts = Counter(all_words)
min_freq = 5
min_length = 3
df['filtered_text'] = df['cleaned_text'].apply(
    lambda x: ' '.join([word for word in x.split()
    if word_counts[word] >= min_freq and len(word) >= min_length])
)

top_categories = df['category'].value_counts().head(15).index
df = df[df['category'].isin(top_categories)]


from imblearn.over_sampling import RandomOverSampler
X = df['filtered_text']
y = df['category']
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X.to_frame(), y)
df_balanced = pd.DataFrame({'text': X_resampled['filtered_text'], 'category': y_resampled})

df_balanced.to_csv('preprocessed_news.csv', index=False)
```

```python
# display distribution after preprocessing

df_balanced['text_length'] = df_balanced['text'].str.len()
fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 18))

# Plot 1: Distribution of category
sns.histplot(data=df_balanced, x='category', bins=30, ax=ax1)
ax1.set_title('Distribution of Category')
ax1.set_xlabel('Category')
ax1.set_ylabel('Count')
plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')

# Plot 2: Top 20 words bar chart
all_words = ' '.join(df_balanced['text']).split()
word_counts = Counter(all_words)
top_words = word_counts.most_common(20)
words, counts = zip(*top_words)

sns.barplot(x=list(counts), y=list(words), palette='viridis', ax=ax2)
ax2.set_title('Top 20 Most Frequent Words')
ax2.set_xlabel('Count')
ax2.set_ylabel('Words')


# Plot 3: Overall word cloud visualization
text = ' '.join(df_balanced['text'])
wordcloud = WordCloud(width=800, height=400,
                     background_color='white',
                     max_words=100,
                     colormap='viridis').generate(text)

ax3.imshow(wordcloud)
ax3.set_title('Overall Word Cloud')
ax3.axis('off')

plt.tight_layout()
plt.show()

```


```python
# Add dropdown to show top 15 frequent words by category
from ipywidgets import interact, Dropdown

def show_category_top_words(category):
    plt.figure(figsize=(10, 6))

    # Get text for selected category
    category_text = ' '.join(df_balanced[df_balanced['category'] == category]['text'])

    # Count word frequencies
    words = category_text.split()
    word_counts = Counter(words)

    # Get top 15 words
    top_words = word_counts.most_common(15)
    words, counts = zip(*top_words)

    # Create bar chart
    sns.barplot(x=list(counts), y=list(words), palette='viridis')
    plt.title(f'Top 15 Most Frequent Words in Category: {category}')
    plt.xlabel('Count')
    plt.ylabel('Words')
    plt.tight_layout()
    plt.show()

# This will create an interactive dropdown in the notebook
interact(show_category_top_words,
         category=Dropdown(options=sorted(df_balanced['category'].unique()),
                          description='Category:'))
```


3. Topic Modeling

* LDA

```python
# init

from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.decomposition import TruncatedSVD, NMF, LatentDirichletAllocation
from bertopic import BERTopic
import pyLDAvis
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Topic number
n_topics = 10
```

```python
from tqdm import tqdm
from sklearn.decomposition import LatentDirichletAllocation
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np

# 2. LDA (Latent Dirichlet Allocation)

n_topics = 15

print("Training LDA model...")

# åˆ›å»ºè¯é¢‘çŸ©é˜µï¼ˆç®€åŒ–æ‰¹å¤„ç†è¿‡ç¨‹ï¼‰
def process_texts_in_batches(texts, batch_size=1000):
    with tqdm(total=len(texts), desc="Processing texts") as pbar:
        processed_texts = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            processed_texts.extend(batch)
            pbar.update(len(batch))
    return processed_texts

# ä¼˜åŒ–çš„CountVectorizerè®¾ç½®
count_vectorizer = CountVectorizer(
    max_features=2000,    
    min_df=10,           # å¢åŠ æœ€å°æ–‡æ¡£é¢‘ç‡é˜ˆå€¼
    max_df=0.8,          # é™ä½æœ€å¤§æ–‡æ¡£é¢‘ç‡é˜ˆå€¼
    stop_words='english',
    token_pattern=r'(?u)\b\w{3,}\b'  # åªä¿ç•™é•¿åº¦â‰¥3çš„è¯
)

# å¤„ç†æ–‡æœ¬
print("Vectorizing documents...")
processed_texts = process_texts_in_batches(df['cleaned_text'])
with tqdm(desc="Creating document-term matrix") as pbar:
    count_matrix = count_vectorizer.fit_transform(processed_texts)
    pbar.update(1)

# ä¼˜åŒ–çš„LDAæ¨¡å‹
lda_model = LatentDirichletAllocation(
    n_components=n_topics,
    random_state=42,
    max_iter=20,
    learning_method='online',
    batch_size=128,
    evaluate_every=2,
    verbose=1
)

# è®­ç»ƒLDAæ¨¡å‹
print("Training LDA model...")
lda_output = lda_model.fit_transform(count_matrix)

# è·å–ä¸»é¢˜è¯ï¼ˆé¿å…ä½¿ç”¨å¹¶è¡Œå¤„ç†ï¼‰
print("Extracting topics...")
feature_names = count_vectorizer.get_feature_names_out()
lda_topics = {}

# ä½¿ç”¨æ™®é€šå¾ªç¯æ›¿ä»£å¹¶è¡Œå¤„ç†
for topic_idx, topic in enumerate(tqdm(lda_model.components_, desc="Processing topics")):
    top_words = [feature_names[i] for i in topic.argsort()[:-10:-1]]
    lda_topics[f"Topic {topic_idx+1}"] = top_words
    print(f"Topic {topic_idx+1}: {', '.join(top_words)}")

# ä¿å­˜ç»“æœ
lda_results = {
    'model': lda_model,
    'vectorizer': count_vectorizer,
    'output': lda_output,
    'topics': lda_topics
}
```

```python
def visualize_lda_results(lda_model, count_vectorizer, lda_output, n_words=10):
    # 1. ä¸»é¢˜-è¯è¯­åˆ†å¸ƒå¯è§†åŒ–
    feature_names = count_vectorizer.get_feature_names_out()

    # åˆ›å»ºä¸€ä¸ªå¤§å›¾ï¼ŒåŒ…å«æ‰€æœ‰ä¸»é¢˜
    n_topics = len(lda_model.components_)
    n_rows = (n_topics + 4) // 5  # æ¯è¡Œ5ä¸ªä¸»é¢˜
    fig = plt.figure(figsize=(20, 4*n_rows))

    for i, topic in enumerate(lda_model.components_):
        plt.subplot(n_rows, 5, i + 1)
        top_words_idx = topic.argsort()[:-n_words-1:-1]
        top_words = [feature_names[idx] for idx in top_words_idx]
        top_weights = topic[top_words_idx]

        plt.barh(top_words, top_weights)
        plt.title(f'Topic {i+1}')
        plt.xlabel('Weight')

    plt.tight_layout()
    plt.show()

    # 2. ä¸»é¢˜åˆ†å¸ƒçƒ­åŠ›å›¾
    plt.figure(figsize=(12, 8))
    topic_term_matrix = pd.DataFrame(
        lda_model.components_,
        columns=feature_names,
        index=[f'Topic {i+1}' for i in range(n_topics)]
    )
    sns.heatmap(topic_term_matrix.iloc[:, :30], cmap='YlOrRd')
    plt.title('Topic-Term Heatmap')
    plt.xlabel('Terms')
    plt.ylabel('Topics')
    plt.show()

    # 3. æ–‡æ¡£-ä¸»é¢˜åˆ†å¸ƒ
    doc_topics = pd.DataFrame(
        lda_output,
        columns=[f'Topic {i+1}' for i in range(n_topics)]
    )

    plt.figure(figsize=(10, 6))
    doc_topics.mean().plot(kind='bar')
    plt.title('Average Topic Distribution Across Documents')
    plt.xlabel('Topics')
    plt.ylabel('Average Weight')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # 4. ä¸»é¢˜ç›¸å…³æ€§
    plt.figure(figsize=(10, 8))
    topic_corr = np.corrcoef(lda_output.T)
    sns.heatmap(
        topic_corr,
        annot=True,
        cmap='coolwarm',
        xticklabels=[f'T{i+1}' for i in range(n_topics)],
        yticklabels=[f'T{i+1}' for i in range(n_topics)]
    )
    plt.title('Topic Correlations')
    plt.show()

    # 5. æ‰“å°æ¯ä¸ªä¸»é¢˜çš„å…³é”®è¯
    print("\nTop words in each topic:")
    for i, topic in enumerate(lda_model.components_):
        top_words_idx = topic.argsort()[:-n_words-1:-1]
        top_words = [feature_names[idx] for idx in top_words_idx]
        print(f"\nTopic {i+1}:")
        print(", ".join(top_words))

# ä½¿ç”¨è¿™ä¸ªå‡½æ•°æ¥å¯è§†åŒ–LDAç»“æœ
visualize_lda_results(lda_model, count_vectorizer, lda_output)
```
#  implementation of sentiment analysis

```python
import pandas as pd
import numpy as np
import re
import spacy
from spacy import displacy
from tqdm import tqdm
tqdm.pandas()

# åŠ è½½æ•°æ®å’Œæ¨¡å‹
nlp = spacy.load("en_core_web_sm", disable=["parser", "ner"])
df = pd.read_csv("preprocessed_news.csv")

# å¢å¼ºçš„æƒ…æ„Ÿåˆ†æé¢„å¤„ç†
def enhanced_sentiment_preprocess(text):
    """ä¿ç•™æƒ…æ„Ÿç›¸å…³è¯æ±‡å’Œä¸Šä¸‹æ–‡"""
    # æ¸…ç†æ–‡æœ¬
    text = re.sub(r"http\S+|www\S+|https\S+", "", str(text).lower())
    text = re.sub(r"[^a-zA-Z\s'â€™]", "", text)

    # å¤„ç†å¦å®šå’Œå¼ºè°ƒ
    text = re.sub(r"\b(not|never|no)\b", " not_", text)
    text = re.sub(r"\b(very|really|extremely)\b", " very_", text)

    # æå–æƒ…æ„Ÿç›¸å…³è¯æ±‡
    doc = nlp(text)
    tokens = []
    for token in doc:
        # ä¿ç•™å½¢å®¹è¯ã€å‰¯è¯ã€åŠ¨è¯ã€å¦å®šè¯ã€æƒ…æ„Ÿåè¯
        if (token.pos_ in {"ADJ", "ADV", "VERB", "NOUN"}) or \
           (token.dep_ == "neg") or \
           (token.text.startswith(("not_", "very_"))):
            tokens.append(token.lemma_)

    return " ".join(tokens)

# åº”ç”¨é¢„å¤„ç†
df["sentiment_text"] = df["text"].progress_apply(enhanced_sentiment_preprocess)
```
### Sentiment Analysis

```python
# é¦–å…ˆç¡®ä¿å®‰è£…æ­£ç¡®ç‰ˆæœ¬çš„åº“


# ç„¶åå¯¼å…¥åº“
import pandas as pd
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from textblob import TextBlob
from transformers import pipeline
from tqdm import tqdm
import numpy as np  # ç¡®ä¿è¿™æ˜¯1.24.0ç‰ˆæœ¬

print(f"ä½¿ç”¨çš„NumPyç‰ˆæœ¬: {np.__version__}")  # åº”è¯¥æ˜¾ç¤º1.24.x

tqdm.pandas()

# åˆå§‹åŒ–å„åˆ†ææ¨¡å‹
vader = SentimentIntensityAnalyzer()

# å®‰å…¨åœ°åˆå§‹åŒ–transformeræ¨¡å‹
try:
    sentiment_pipeline = pipeline("sentiment-analysis",
                                model="distilbert-base-uncased-finetuned-sst-2-english")
except Exception as e:
    print(f"æ— æ³•åŠ è½½transformeræ¨¡å‹: {e}")
    sentiment_pipeline = None

def ensemble_sentiment_analysis(text):
    """é›†æˆå¤šç§æƒ…æ„Ÿåˆ†ææ–¹æ³•"""
    # å¤„ç†ç¼ºå¤±å€¼
    if pd.isna(text):
        text = ""

    # VADERåˆ†æ
    vader_scores = vader.polarity_scores(text)

    # TextBlobåˆ†æ
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity

    # Transformeræ¨¡å‹åˆ†æ
    transformer_score = 0
    if sentiment_pipeline is not None:
        try:
            transformer_result = sentiment_pipeline(text[:512])[0]  # é™åˆ¶é•¿åº¦
            transformer_score = (1 if transformer_result["label"] == "POSITIVE" else -1) * transformer_result["score"]
        except Exception as e:
            print(f"Transformeråˆ†æå‡ºé”™: {e}")

    # åŠ æƒç»¼åˆå¾—åˆ†
    combined_score = (vader_scores["compound"] * 0.4 +
                     polarity * 0.3 +
                     transformer_score * 0.3)

    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    return {
        "vader_compound": vader_scores["compound"],
        "textblob_polarity": polarity,
        "transformer_score": transformer_score,
        "combined_score": combined_score,
        "sentiment_label": "positive" if combined_score > 0.1 else
                          "negative" if combined_score < -0.1 else
                          "neutral"
    }

# åº”ç”¨æƒ…æ„Ÿåˆ†æ
print("analyzing sentiment...")
sentiment_results = df["text"].progress_apply(ensemble_sentiment_analysis)
sentiment_df = pd.DataFrame(list(sentiment_results))
df = pd.concat([df, sentiment_df], axis=1)

df.to_csv("sentiment.csv", index=False)
print(df)
```

### 3. Entity level sentiment analysis


```python
import spacy
from tqdm import tqdm, trange
import pandas as pd
tqdm.pandas()
import warnings
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)


df = pd.read_csv("sentiment.csv")

df = df.dropna()

# åŠ è½½è‹±æ–‡æ¨¡å‹ï¼ˆä»…å¯ç”¨NERéœ€è¦çš„ç»„ä»¶ï¼‰
nlp_ner = spacy.load("en_core_web_sm", disable=["parser", "tagger", "lemmatizer"])

def extract_entities_with_sentiment(row):
    """
    ä¼˜åŒ–ç‰ˆçš„å®ä½“æƒ…æ„Ÿå…³è”æå–
    è¾“å…¥: DataFrameçš„ä¸€è¡Œ(åŒ…å«textå’Œæƒ…æ„Ÿåˆ†æ•°)
    è¾“å‡º: å®ä½“åŠå…¶æƒ…æ„Ÿä¿¡æ¯çš„å­—å…¸
    """
    text = row["text"]
    doc = nlp_ner(text)
    entities = {}

    for ent in doc.ents:
        if ent.label_ in ["PERSON", "ORG", "GPE", "PRODUCT"]:
            # è·å–å®ä½“ä¸Šä¸‹æ–‡çª—å£
            window_size = 10  # å‰åå„å–10ä¸ªè¯ä½œä¸ºä¸Šä¸‹æ–‡
            start = max(0, ent.start - window_size)
            end = min(len(doc), ent.end + window_size)
            context = doc[start:end].text

            # ä½¿ç”¨å·²æœ‰æƒ…æ„Ÿåˆ†æ•°(ä¼˜åŒ–æ€§èƒ½)
            entities[ent.text] = {
                "type": ent.label_,
                "sentiment": row["combined_score"],  # ä½¿ç”¨æ•´å¥æƒ…æ„Ÿåˆ†æ•°
                "label": row["sentiment_label"],
                "context": context,
                "entity_text": ent.text
            }
    return entities
# æµ‹è¯•ç¤ºä¾‹
sample_row = df.iloc[6]  # å–ç¬¬5æ¡æ•°æ®
print("Example text:", sample_row)
print("Example result:")
print(extract_entities_with_sentiment(sample_row))
```
ç»“æœ

```python
Example text: text                 yale professor leaving spot exact reason trump...
category                                                      POLITICS
sentiment_text       professor leave spot exact reason trump brutal...
vader_compound                                                 -0.6808
textblob_polarity                                             -0.15625
transformer_score                                             -0.92486
combined_score                                               -0.596653
sentiment_label                                               negative
Name: 6, dtype: object
Example result:
{'yale': {'type': 'ORG', 'sentiment': np.float64(-0.5966531253528595), 'label': 'negative', 'context': 'yale professor leaving spot exact reason trump brutal attack university jason', 'entity_text': 'yale'}, 'jason stanley': {'type': 'PERSON', 'sentiment': np.float64(-0.5966531253528595), 'label': 'negative', 'context': 'yale professor leaving spot exact reason trump brutal attack university jason stanley expert fascism pointed grave sign future academic freedom', 'entity_text': 'jason stanley'}}
```


```python
# æ‰¹é‡å¤„ç†å‡½æ•°ï¼ˆä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼‰
def batch_extract_entities(df, batch_size=1000):
    """
    åˆ†æ‰¹å¤„ç†DataFrameï¼Œé¿å…å†…å­˜ä¸è¶³
    """
    results = []
    length = len(df)
    for i in trange(0, length, batch_size):
        batch = df.iloc[i:i+batch_size]
        batch_results = batch.apply(extract_entities_with_sentiment, axis=1)
        results.append(batch_results)
    return pd.concat(results)

# åº”ç”¨åˆ°æ•´ä¸ªæ•°æ®é›†
print("NER running...")
df["entity_sentiments"] = batch_extract_entities(df)

```

ç»“æœ

```py
NER running...
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495/495 [24:56<00:00
```

### 4. Sentiment Analysis Visualization

```python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from wordcloud import WordCloud

# è®¾ç½® seaborn ç»˜å›¾é£æ ¼
sns.set_style("whitegrid")  # è®¾ç½® seaborn çš„é£æ ¼ï¼Œè¿™é‡Œä½¿ç”¨ whitegrid é£æ ¼ï¼Œä½ ä¹Ÿå¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©å…¶ä»–é£æ ¼
sns.set_palette("husl")



# 1. æ•´ä½“æƒ…æ„Ÿåˆ†å¸ƒ
plt.figure(figsize=(10, 6))
ax = sns.countplot(data=df, x='sentiment_label',
                 order=['positive', 'neutral', 'negative'],
                 palette={'positive': '#4caf50', 'neutral': '#9e9e9e', 'negative': '#f44336'})
plt.title('News sentiment label distribution', fontsize=14, pad=20)
plt.xlabel('Sentiment classification', fontsize=12)
plt.ylabel('quantity', fontsize=12)

# æ·»åŠ æ•°å€¼æ ‡ç­¾
for p in ax.patches:
    ax.annotate(f'{p.get_height():.0f}',
               (p.get_x() + p.get_width() / 2., p.get_height()),
               ha='center', va='center',
               xytext=(0, 5),
               textcoords='offset points')

plt.tight_layout()
plt.show()

```
\

![image](https://github.com/user-attachments/assets/7205e77e-fd5b-4e93-803c-fb5c5bf68f18)

```python
# 2. å¤šæ¨¡å‹æƒ…æ„Ÿåˆ†æ•°åˆ†å¸ƒå¯¹æ¯”
plt.figure(figsize=(14, 8))

# åˆ›å»ºå­å›¾ç½‘æ ¼
fig, axes = plt.subplots(2, 2, figsize=(14, 12))

# VADERåˆ†æ•°åˆ†å¸ƒ
sns.histplot(data=df, x='vader_compound', bins=30, kde=True, ax=axes[0, 0])
axes[0, 0].set_title('VADER sentiment score distribution')
axes[0, 0].axvline(0, color='k', linestyle='--')

# TextBlobåˆ†æ•°åˆ†å¸ƒ
sns.histplot(data=df, x='textblob_polarity', bins=30, kde=True, ax=axes[0, 1])
axes[0, 1].set_title('TextBlobsentiment score distribution')
axes[0, 1].axvline(0, color='k', linestyle='--')

# Transformeråˆ†æ•°åˆ†å¸ƒ
sns.histplot(data=df, x='transformer_score', bins=30, kde=True, ax=axes[1, 0])
axes[1, 0].set_title('Transformersentiment score distribution')
axes[1, 0].axvline(0, color='k', linestyle='--')

# ç»¼åˆåˆ†æ•°åˆ†å¸ƒ
sns.histplot(data=df, x='combined_score', bins=30, kde=True, ax=axes[1, 1])
axes[1, 1].set_title('Comprehensive sentiment score distribution')
axes[1, 1].axvline(0, color='k', linestyle='--')

plt.tight_layout()
plt.show()
```

![image](https://github.com/user-attachments/assets/6ecd285d-d165-44a6-b47e-c2eea24279bf)



```py
# 3. å„ç±»åˆ«æƒ…æ„Ÿåˆ†å¸ƒ
plt.figure(figsize=(14, 8))

# æŒ‰ç±»åˆ«åˆ†ç»„è®¡ç®—å¹³å‡æƒ…æ„Ÿåˆ†æ•°
category_sentiment = df.groupby('category')['combined_score'].agg(['mean', 'count'])
category_sentiment = category_sentiment[category_sentiment['count'] > 50]  # è¿‡æ»¤æ ·æœ¬é‡å°‘çš„ç±»åˆ«

# ç»˜åˆ¶æ¡å½¢å›¾
ax = sns.barplot(data=category_sentiment.reset_index(),
                x='mean', y='category',
                palette='coolwarm')
plt.axvline(0, color='k', linestyle='--')
plt.title('Average sentiment score of each news category', fontsize=14, pad=20)
plt.xlabel('average sentiment score', fontsize=12)
plt.ylabel('News categories', fontsize=12)

# æ·»åŠ æ•°å€¼æ ‡ç­¾
for i, (mean, count) in enumerate(zip(category_sentiment['mean'], category_sentiment['count'])):
    ax.text(mean, i, f'{mean:.2f}\n(n={count})',
            va='center', ha='left' if mean < 0 else 'right',
            color='white' if abs(mean) > 0.2 else 'black')

plt.tight_layout()
plt.show()
```
![image](https://github.com/user-attachments/assets/176cbe3d-92a5-489e-9c2b-7d00d00fd545)

```py
# 4. æƒ…æ„Ÿè¯äº‘å¯¹æ¯”
def generate_sentiment_wordcloud(sentiment_type='positive', colormap='Greens'):
    """ç”Ÿæˆæƒ…æ„Ÿè¯äº‘"""
    subset = df[df['sentiment_label'] == sentiment_type]
    text = ' '.join(subset['sentiment_text'])

    # è¿‡æ»¤åœç”¨è¯
    stopwords = set(['say', 'said', 'will', 'one', 'year', 'new'])

    wordcloud = WordCloud(
        width=800, height=400,
        background_color="white",
        colormap=colormap,
        max_words=100,
        stopwords=stopwords,
        contour_width=3,
        contour_color='steelblue'
    ).generate(text)

    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud)
    plt.title(f'{sentiment_type.capitalize()}Emotion word cloud', fontsize=14, pad=20)
    plt.axis("off")
    plt.show()

# ç”Ÿæˆæ­£é¢å’Œè´Ÿé¢è¯äº‘
generate_sentiment_wordcloud('positive', 'Greens')
generate_sentiment_wordcloud('negative', 'Reds')
```


![image](https://github.com/user-attachments/assets/6577edbb-ecde-46f9-bdf3-85206dd6f557)


![image](https://github.com/user-attachments/assets/0c53465a-d3ab-4774-ba26-534bc09fd53c)

```py
# 5. å®ä½“æƒ…æ„Ÿåˆ†æ
from collections import defaultdict

# æå–æ‰€æœ‰å®ä½“åŠå…¶æƒ…æ„Ÿåˆ†æ•°
entity_sentiments = defaultdict(list)
for entities in df['entity_sentiments']:
    for ent, data in entities.items():
        entity_sentiments[ent].append(data['sentiment'])

# è®¡ç®—æ¯ä¸ªå®ä½“çš„å¹³å‡æƒ…æ„Ÿ
entity_avg_sentiment = {
    ent: np.mean(scores)
    for ent, scores in entity_sentiments.items()
    if len(scores) >= 5  # åªè€ƒè™‘å‡ºç°5æ¬¡ä»¥ä¸Šçš„å®ä½“
}

# è½¬æ¢ä¸ºDataFrame
entity_df = pd.DataFrame({
    'entity': list(entity_avg_sentiment.keys()),
    'avg_sentiment': list(entity_avg_sentiment.values()),
    'count': [len(entity_sentiments[ent]) for ent in entity_avg_sentiment.keys()]
})

# ç­›é€‰æœ€å…·ä»£è¡¨æ€§çš„å®ä½“
top_entities = entity_df.nlargest(10, 'count')

# å¯è§†åŒ–
plt.figure(figsize=(14, 8))
ax = sns.barplot(data=top_entities, x='avg_sentiment', y='entity',
                palette='coolwarm')
plt.axvline(0, color='k', linestyle='--')
plt.title('High-frequency entity sentiment analysis (occurrence â‰¥ 5 times', fontsize=14, pad=20)
plt.xlabel('average sentiment score', fontsize=12)
plt.ylabel('Entity name', fontsize=12)

# æ·»åŠ æ•°å€¼æ ‡ç­¾
for p in ax.patches:
    width = p.get_width()
    ax.annotate(f'{width:.2f}',
                (width, p.get_y() + p.get_height() / 2.),
                ha='left' if width > 0 else 'right',
                va='center',
                xytext=(5 if width > 0 else -5, 0),
                textcoords='offset points')

plt.tight_layout()
plt.show()
```

```py
from ipywidgets import interact, widgets
import plotly.express as px

# 6.1 äº¤äº’å¼æƒ…æ„Ÿæ¢ç´¢
@interact
def explore_sentiment(category=widgets.Dropdown(
    options=sorted(df['category'].unique())),
    score_type=widgets.Dropdown(
    options=['combined_score', 'vader_compound', 'textblob_polarity'])):
    """äº¤äº’å¼æ¢ç´¢ä¸åŒç±»åˆ«çš„æƒ…æ„Ÿåˆ†å¸ƒ"""
    subset = df[df['category'] == category]

    fig = px.histogram(subset, x=score_type,
                      nbins=30,
                      title=f'{category} category {score_type} score_type',
                      color_discrete_sequence=['#636EFA'])

    fig.update_layout(
        xaxis_title='sentiment score',
        yaxis_title='quantity',
        bargap=0.1
    )
    fig.add_vline(x=0, line_dash="dash", line_color="black")
    fig.show()

# 6.2 äº¤äº’å¼å®ä½“æ¢ç´¢
if len(entity_df) > 0:
    @interact
    def explore_entity(min_count=widgets.IntSlider(
        min=1, max=entity_df['count'].max(), value=5)):
        """äº¤äº’å¼æ¢ç´¢å®ä½“æƒ…æ„Ÿ"""
        filtered = entity_df[entity_df['count'] >= min_count]

        fig = px.scatter(filtered, x='avg_sentiment', y='entity',
                        size='count', color='avg_sentiment',
                        color_continuous_scale='RdYlGn',
                        title=f'Entity sentiment analysis (occurrence â‰¥{min_count} Second - rate)')

        fig.update_layout(
            xaxis_title='average sentiment score',
            yaxis_title='Entity name',
            coloraxis_colorbar=dict(title="sentiment score")
        )
        fig.add_vline(x=0, line_dash="dash", line_color="black")
        fig.show()
```
![image](https://github.com/user-attachments/assets/3a432b12-ab5e-417a-a43d-83378cdc2c40)


![image](https://github.com/user-attachments/assets/e7c6a9b9-e837-4d85-9e1d-9b6ead0d031c)


```py
# 7. ç”Ÿæˆé«˜çº§åˆ†ææŠ¥å‘Š
def generate_sentiment_report():
    """ç”Ÿæˆç»¼åˆæƒ…æ„Ÿåˆ†ææŠ¥å‘Š"""
    report = {
        'overall_sentiment': {
            'positive': len(df[df['sentiment_label'] == 'positive']),
            'neutral': len(df[df['sentiment_label'] == 'neutral']),
            'negative': len(df[df['sentiment_label'] == 'negative'])
        },
        'top_positive_category': df.groupby('category')['combined_score'].mean().idxmax(),
        'top_negative_category': df.groupby('category')['combined_score'].mean().idxmin(),
        'most_positive_entity': max(entity_avg_sentiment.items(), key=lambda x: x[1])[0] if entity_avg_sentiment else "N/A",
        'most_negative_entity': min(entity_avg_sentiment.items(), key=lambda x: x[1])[0] if entity_avg_sentiment else "N/A"
    }

    # æ‰“å°æŠ¥å‘Š
    print("="*50)
    print("Sentiment Analysis Report".center(40))
    print("="*50)
    print(f"\nOverall Distribution:")
    print(f"- Positive: {report['overall_sentiment']['positive']}")
    print(f"- Neutral: {report['overall_sentiment']['neutral']}")
    print(f"- Negative: {report['overall_sentiment']['negative']}")

    print(f"\nThe most positive category: {report['top_positive_category']}")
    print(f"The most negative category: {report['top_negative_category']}")

    if entity_avg_sentiment:
        print(f"\nThe most positive entity: {report['most_positive_entity']}")
        print(f"The most negative entity: {report['most_negative_entity']}")

    print("\n" + "="*50)

# ç”ŸæˆæŠ¥å‘Š
generate_sentiment_report()
```


ç»“æœ

```python
==================================================
       Sentiment Analysis Report        
==================================================

Overall Distribution:
- Positive: 203339
- Neutral: 69424
- Negative: 221760

The most positive category: TRAVEL
The most negative category: POLITICS

The most positive entity: lewis lee rachel roy nicole
The most negative entity: geek worst decor

==================================================
```

### 5.1 Entity Sentiment Comparision

```python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from collections import defaultdict

def compare_entities(df, entity1=None, entity2=None):
    """
    æ¯”è¾ƒä¸¤ä¸ªå®ä½“çš„æƒ…æ„Ÿè¡¨ç°
    å‚æ•°:
        df: åŒ…å«å®ä½“æƒ…æ„Ÿæ•°æ®çš„DataFrame
        entity1: ç¬¬ä¸€ä¸ªå®ä½“åç§° (å¯é€‰)
        entity2: ç¬¬äºŒä¸ªå®ä½“åç§° (å¯é€‰)
    """
    # æ£€æŸ¥entity_sentimentsåˆ—æ˜¯å¦å­˜åœ¨
    if "entity_sentiments" not in df.columns:
        print("LACK 'entity_sentiments' COL")
        return

    # å¦‚æœæ²¡æœ‰æŒ‡å®šå®ä½“ï¼Œè‡ªåŠ¨é€‰æ‹©æ•°æ®ä¸­æœ€å¸¸è§çš„ä¸¤ä¸ªå®ä½“
    if entity1 is None or entity2 is None:
        entity_counts = defaultdict(int)
        for entities in df["entity_sentiments"]:
            if isinstance(entities, dict):
                for ent in entities.keys():
                    entity_counts[ent] += 1

        if len(entity_counts) < 2:
            print("NO ENOUGH DATA")
            return

        # é€‰æ‹©å‡ºç°é¢‘ç‡æœ€é«˜çš„ä¸¤ä¸ªä¸åŒå®ä½“
        top_entities = sorted(entity_counts.items(), key=lambda x: x[1], reverse=True)[:2]
        entity1, entity2 = top_entities[0][0], top_entities[1][0]
        print(f"Entity Auto Selected: {entity1} vs {entity2}")

    # æ”¶é›†å®ä½“æƒ…æ„Ÿæ•°æ®
    entity1_data = []
    entity2_data = []

    for _, row in df.iterrows():
        entities = row["entity_sentiments"]
        if isinstance(entities, dict):
            if entity1 in entities:
                entity1_data.append(entities[entity1].get("sentiment", 0))
            if entity2 in entities:
                entity2_data.append(entities[entity2].get("sentiment", 0))

    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿæ•°æ®
    if not entity1_data or not entity2_data:
        print(f"NO ENOUGH DATA (E1: {len(entity1_data)}, E2: {len(entity2_data)})")
        return

    # å¯è§†åŒ–æ¯”è¾ƒ
    plt.figure(figsize=(14, 6))

    # å­å›¾1: æƒ…æ„Ÿåˆ†å¸ƒç›´æ–¹å›¾
    plt.subplot(1, 2, 1)
    sns.histplot(entity1_data, bins=15, color="blue", kde=True, alpha=0.6, label=entity1)
    sns.histplot(entity2_data, bins=15, color="orange", kde=True, alpha=0.6, label=entity2)
    plt.axvline(np.mean(entity1_data), color="blue", linestyle="--")
    plt.axvline(np.mean(entity2_data), color="orange", linestyle="--")
    plt.title(f"{entity1} vs {entity2} Sentiment Distribution")
    plt.xlabel("Score")
    plt.legend()

    # å­å›¾2: ç®±çº¿å›¾æ¯”è¾ƒ
    plt.subplot(1, 2, 2)
    plot_data = pd.DataFrame({
        "Entity": [entity1]*len(entity1_data) + [entity2]*len(entity2_data),
        "Sentiment": entity1_data + entity2_data
    })
    sns.boxplot(data=plot_data, x="Entity", y="Sentiment",
                palette={"blue", "orange"}, width=0.4)
    plt.title("Entity Sentiment Comparison")
    plt.xticks(rotation=45)

    plt.tight_layout()
    plt.show()

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\n{entity1} Sentiment Analysis Result:")
    print(f"- AVG: {np.mean(entity1_data):.2f}")
    print(f"- STD: {np.std(entity1_data):.2f}")
    print(f"- Len: {len(entity1_data)}")

    print(f"\n{entity2} Sentiment Analysis Result:")
    print(f"- AVG: {np.mean(entity2_data):.2f}")
    print(f"- STD: {np.std(entity2_data):.2f}")
    print(f"- Len: {len(entity2_data)}")

    # æ‰§è¡Œtæ£€éªŒ (å¦‚æœæ•°æ®è¶³å¤Ÿ)
    if len(entity1_data) > 1 and len(entity2_data) > 1:
        from scipy import stats
        t_stat, p_value = stats.ttest_ind(entity1_data, entity2_data)
        print(f"\nT-test result:")
        print(f"- T: {t_stat:.2f}")
        print(f"- p: {p_value:.4f}")
        if p_value < 0.05:
            print("-> significant difference(p < 0.05)")
        else:
            print("-> no significant difference")


compare_entities(df)
```
Entity Auto Selected: donald trump vs america

![image](https://github.com/user-attachments/assets/b565554c-d31f-4ca9-97a4-0121f8be711a)


```python

donald trump Sentiment Analysis Result:
- AVG: -0.16
- STD: 0.40
- Len: 7368

america Sentiment Analysis Result:
- AVG: 0.04
- STD: 0.48
- Len: 6888

T-test result:
- T: -27.85
- p: 0.0000
-> significant difference(p < 0.05)
```
### 5.2 sentiment alert system

```py
def sentiment_alert_system(df, threshold=-0.2):
    """
    è´Ÿé¢èˆ†æƒ…é¢„è­¦ç³»ç»Ÿ
    å‚æ•°:
        df: åŒ…å«æƒ…æ„Ÿåˆ†æç»“æœçš„DataFrame
        threshold: è´Ÿé¢æƒ…æ„Ÿé˜ˆå€¼ (é»˜è®¤-0.2)
    """
    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_columns = ['entity_sentiments']
    missing_cols = [col for col in required_columns if col not in df.columns]

    if missing_cols:
        print(f"âš ï¸ LACK COL: {missing_cols}")
        return

    # å°è¯•ä¸åŒçš„æƒ…æ„Ÿåˆ†æ•°åˆ— (æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥)
    score_columns = ['combined_score', 'vader_compound', 'textblob_polarity']
    score_col = next((col for col in score_columns if col in df.columns), None)

    if score_col is None:
        print("âš ï¸ NO ENOUGH DATA")
        return

    print(f"Use '{score_col}' to determine")

    # æŒ‰ç±»åˆ«æ£€æµ‹è´Ÿé¢æƒ…ç»ª
    negative_news = df[df[score_col] < threshold]

    if len(negative_news) > 0:
        print(f"\nâš ï¸ {len(negative_news)} negative news detected. (score < {threshold})")

        # ç»Ÿè®¡é«˜é¢‘è´Ÿé¢å®ä½“
        negative_entities = {}
        for entities in negative_news["entity_sentiments"]:
            # ç¡®ä¿entity_sentimentsæ˜¯å­—å…¸æ ¼å¼
            if isinstance(entities, str):
                try:
                    entities = eval(entities)  # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå­—å…¸
                except:
                    continue

            if isinstance(entities, dict):
                for ent, data in entities.items():
                    if isinstance(data, dict) and 'sentiment' in data:
                        if data['sentiment'] < threshold:
                            negative_entities[ent] = negative_entities.get(ent, 0) + 1

        # å±•ç¤ºTopè´Ÿé¢å®ä½“
        if negative_entities:
            top_negative = sorted(negative_entities.items(),
                                 key=lambda x: x[1], reverse=True)[:5]
            print("\nğŸ”¥ Top negative related entity:")
            for ent, count in top_negative:
                print(f"- {ent}: {count}")
        else:
            print("\nNo negative related entity found")

        # å±•ç¤ºä»£è¡¨æ€§è´Ÿé¢æ–°é—»
        print("\nğŸ“Œ Representative Negative news:")
        sample_size = min(3, len(negative_news))
        for idx, row in negative_news.nsmallest(sample_size, score_col).iterrows():
            print(f"\n[{idx}] Score: {row[score_col]:.2f}")

            # å°è¯•è·å–æ ‡é¢˜æˆ–æ–‡æœ¬ç‰‡æ®µ
            if 'headline' in df.columns:
                print(f"Title: {row['headline']}")
            elif 'text' in df.columns:
                preview = row['text'][:50] + "..." if len(row['text']) > 50 else row['text']
                print(f"Content: {preview}")

            # æ˜¾ç¤ºå…³è”å®ä½“
            entities = row['entity_sentiments']
            if isinstance(entities, str):
                try:
                    entities = eval(entities)
                except:
                    entities = {}

            if isinstance(entities, dict):
                print("Key entity:", ", ".join(entities.keys()))
    else:
        print("\nâœ… No negative news detected.")

# ä½¿ç”¨ç¤ºä¾‹
print("="*50)
print("Start to find negative news")
print("="*50)
sentiment_alert_system(df)  # ä¼ å…¥æ‚¨çš„DataFrame
```
ç»“æœ

```py
==================================================
Start to find negative news
==================================================
Use 'combined_score' to determine

âš ï¸ 185876 negative news detected. (score < -0.2)

ğŸ”¥ Top negative related entity:
- donald trump: 4148
- america: 2498
- gop: 2206
- california: 1814
- florida: 1306

ğŸ“Œ Representative Negative news:

[78460] Score: -0.98
Content: worst product flop wall street worst product flop ...
Key entity: 

[173147] Score: -0.98
Content: worst product flop wall street worst product flop ...
Key entity: 

[173883] Score: -0.98
Content: worst product flop wall street worst product flop ...
Key entity:
```

6. æŠ€æœ¯æŒ‘æˆ˜è§£å†³æ–¹æ¡ˆ

6.1 é«˜çº§è®½åˆºæ£€æµ‹

```js
from transformers import pipeline

# åŠ è½½è®½åˆºæ£€æµ‹æ¨¡å‹
irony_pipeline = pipeline("text-classification",
                         model="cardiffnlp/twitter-roberta-base-irony")

def detect_irony(text):
    """ä½¿ç”¨Transformeræ¨¡å‹æ£€æµ‹è®½åˆº"""
    try:
        result = irony_pipeline(text[:512])[0]  # é™åˆ¶é•¿åº¦
        return result["label"] == "irony"
    except:
        return False

# åº”ç”¨åˆ°ç–‘ä¼¼è®½åˆºæ–‡æœ¬
potential_irony = df[(df["vader_compound"] > 0) & (df["textblob_polarity"] < 0)]
if len(potential_irony) > 0:
    potential_irony["is_ironic"] = potential_irony["text"].progress_apply(detect_irony)
    print(f"Sum: {potential_irony['is_ironic'].sum()} ironic news detected.")
```
### 6.2 dynamic domain adaptation


```js
def dynamic_domain_adaptation(text, category):
    """åŠ¨æ€é¢†åŸŸé€‚åº”æƒ…æ„Ÿåˆ†æ"""
    # é¢†åŸŸç‰¹å®šè°ƒæ•´è§„åˆ™
    domain_rules = {
        "POLITICS": {
            "boost_words": ["reform", "progress", "bipartisan"],
            "penalty_words": ["scandal", "corruption", "controversy"]
        },
        "TECH": {
            "boost_words": ["innovative", "sleek", "user-friendly"],
            "penalty_words": ["buggy", "outdated", "overpriced"]
        }
    }

    # è·å–åŸºç¡€åˆ†æ•°
    base_score = ensemble_sentiment_analysis(text)["combined_score"]

    # åº”ç”¨é¢†åŸŸè°ƒæ•´
    if category in domain_rules:
        boost = sum(1 for word in domain_rules[category]["boost_words"]
                if word in text.lower()) * 0.05
        penalty = sum(1 for word in domain_rules[category]["penalty_words"]
                     if word in text.lower()) * 0.05
        adjusted_score = base_score + boost - penalty
        return max(-1, min(1, adjusted_score))  # ä¿æŒåœ¨[-1,1]èŒƒå›´å†…

    return base_score

# åº”ç”¨é¢†åŸŸè‡ªé€‚åº”
df["domain_adjusted_score"] = df.progress_apply(
    lambda row: dynamic_domain_adaptation(row["text"], row["category"]), axis=1)

```


```python
import pandas as pd
from mlxtend.preprocessing import TransactionEncoder

def prepare_transaction_data(df):
    """
    æŒ‰è¯¾ç¨‹æ ‡å‡†å‡†å¤‡äº‹åŠ¡æ•°æ®
    ä¿®æ”¹ç‚¹ï¼š
    1. ç§»é™¤ä¸å¿…è¦çš„è¿”å›é¡¹
    2. ç®€åŒ–ç‰¹å¾æå–é€»è¾‘
    3. ç¡®ä¿è¾“å‡ºæ ¼å¼ä¸è¯¾ç¨‹ç¤ºä¾‹å®Œå…¨ä¸€è‡´
    """
    transactions = []
    for _, row in df.iterrows():
        itemset = []

        # å¿…é¡»åŒ…å«æƒ…æ„Ÿæ ‡ç­¾ï¼ˆè¯¾ç¨‹ä¸­çš„Yå˜é‡ï¼‰
        itemset.append(f"sentiment={row['sentiment_label']}")

        # ä»…ä¿ç•™è¯¾ç¨‹è¦æ±‚çš„ç‰¹å¾ç±»å‹
        if 'category' in df.columns:
            itemset.append(f"category={row['category']}")

        if 'entity_sentiments' in df.columns and isinstance(row['entity_sentiments'], dict):
            itemset.extend([f"entity={ent}" for ent in row['entity_sentiments'].keys()])

        transactions.append(itemset)

    # ä¸¥æ ¼æŒ‰è¯¾ç¨‹ç¤ºä¾‹è¿›è¡Œone-hotç¼–ç 
    te = TransactionEncoder()
    te_ary = te.fit(transactions).transform(transactions)
    return pd.DataFrame(te_ary, columns=te.columns_)


# ç”Ÿæˆäº‹åŠ¡æ•°æ®
trans_df = prepare_transaction_data(df)
print("Transition Data example:")
print(trans_df.iloc[0, :20])  # æ˜¾ç¤ºç¬¬ä¸€è¡Œçš„å‰5ä¸ªç‰¹å¾
```

ç»“æœ

```python
Transition Data exampleï¼š
category=BLACK VOICES      False
category=BUSINESS          False
category=COMEDY            False
category=ENTERTAINMENT     False
category=ENVIRONMENT       False
category=FOOD & DRINK      False
category=HEALTHY LIVING    False
category=HOME & LIVING     False
category=PARENTING         False
category=POLITICS           True
category=QUEER VOICES      False
category=SPORTS            False
category=STYLE & BEAUTY    False
category=TRAVEL            False
category=WELLNESS          False
entity=aaron               False
entity=aaron austin        False
entity=aaron bennett       False
entity=aaron brian         False
entity=aaron burr          False
Name: 0, dtype: bool
```



```python
from mlxtend.frequent_patterns import apriori, association_rules

def mine_association_rules(trans_df):
    """
    æŒ‰è¯¾ç¨‹æ ‡å‡†å®ç°å…³è”è§„åˆ™æŒ–æ˜
    ä¿®æ”¹ç‚¹ï¼š
    1. ä½¿ç”¨è¯¾ç¨‹æŒ‡å®šçš„é»˜è®¤å‚æ•°
    2. ç®€åŒ–è§„åˆ™ç­›é€‰é€»è¾‘
    3. è¾“å‡ºæ ¼å¼ä¸è¯¾ç¨‹ç¤ºä¾‹ä¸€è‡´
    """
    # ä½¿ç”¨è¯¾ç¨‹æ¨èå‚æ•°ï¼ˆmin_support=0.1, min_threshold=0.7ï¼‰
    frequent_itemsets = apriori(trans_df, min_support=0.001, use_colnames=True)
    
    # ç”Ÿæˆè§„åˆ™ï¼ˆæŒ‰è¯¾ç¨‹è¦æ±‚ä½¿ç”¨confidenceä½œä¸ºåº¦é‡ï¼‰
    rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.7)
    
    # æŒ‰è¯¾ç¨‹ç¤ºä¾‹æ·»åŠ lengthåˆ—
    frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))

    # ç­›é€‰æœ‰æ•ˆè§„åˆ™ï¼ˆlift>1ï¼‰
    meaningful_rules = rules[rules['lift'] > 1].copy()
    
    meaningful_rules['rule'] = meaningful_rules.apply(
        lambda row: f"{str(row['antecedents'])} â†’ {str(row['consequents'])}",
        axis=1
    )

    return frequent_itemsets, meaningful_rules

# æ‰§è¡ŒæŒ–æ˜
frequent_itemsets, rules = mine_association_rules(trans_df)

# æ˜¾ç¤ºç»“æœï¼ˆæŒ‰è¯¾ç¨‹è¡¨æ ¼æ ¼å¼ï¼‰
print("\nFreq Set Top5:")
print(frequent_itemsets[['itemsets', 'support', 'length']].head())
print("\nRules Top5:")
print(rules[['rule', 'support', 'confidence', 'lift']].head())
```


ç»“æœ

```python

Freq Set Top5:
                   itemsets   support  length
0   (category=BLACK VOICES)  0.066656       1
1       (category=BUSINESS)  0.066699       1
2         (category=COMEDY)  0.066565       1
3  (category=ENTERTAINMENT)  0.066608       1
4    (category=ENVIRONMENT)  0.066699       1

Rules Top5:
                                                rule   support  confidence  \
0  frozenset({'entity=bill maher'}) â†’ frozenset({...  0.001840    0.918264   
1  frozenset({'entity=jimmy kimmel'}) â†’ frozenset...  0.002004    0.797907   
2  frozenset({'entity=john oliver'}) â†’ frozenset(...  0.001213    0.877193   
3  frozenset({'entity=seth'}) â†’ frozenset({'categ...  0.001737    0.914803   
4  frozenset({'entity=stephen colbert'}) â†’ frozen...  0.002283    0.901038   

        lift  
0  13.794971  
1  11.986851  
2  13.177961  
3  13.742971  
4  13.536174
```


```python
import matplotlib.pyplot as plt

def plot_rules(rules, top_n=10):
    """æŒ‰è¯¾ç¨‹é¡¹ç›®ç¤ºä¾‹ç»˜åˆ¶è§„åˆ™çƒ­åŠ›å›¾"""
    if len(rules) == 0:
        print("æ— æœ‰æ•ˆè§„åˆ™å¯å¯è§†åŒ–")
        return

    # å‡†å¤‡æ•°æ® (æŒ‰è¯¾ç¨‹ç¤ºä¾‹æ ¼å¼)
    plot_data = rules.head(top_n).copy()
    plot_data['rule'] = plot_data.apply(
        lambda row: f"{set(row['antecedents'])} â†’ {set(row['consequents'])}",
        axis=1
    )

    # ç»˜åˆ¶çƒ­åŠ›å›¾ (å®Œå…¨æŒ‰è¯¾ç¨‹é£æ ¼)
    plt.figure(figsize=(10, 6))
    plt.scatter(
        plot_data['support'],
        plot_data['confidence'],
        s=plot_data['lift'] * 100,  # ç‚¹å¤§å°è¡¨ç¤ºlift
        c=plot_data['lift'],        # é¢œè‰²è¡¨ç¤ºlift
        alpha=0.6,
        cmap='viridis'
    )

    # æ·»åŠ æ ‡ç­¾ (æŒ‰è¯¾ç¨‹ç¤ºä¾‹)
    for i, row in plot_data.iterrows():
        plt.annotate(
            row['rule'],
            (row['support'], row['confidence']),
            xytext=(5, 5),
            textcoords='offset points',
            fontsize=8
        )

    plt.colorbar(label='Lift')
    plt.xlabel('Support (P(XâˆªY))', fontsize=12)
    plt.ylabel('Confidence (P(Y|X))', fontsize=12)
    plt.title('Association rule heat map (size/color indicates lift)', fontsize=14)
    plt.grid(True, alpha=0.2)
    plt.tight_layout()
    plt.show()

# å¯è§†åŒ–
plot_rules(rules)
```

![image](https://github.com/user-attachments/assets/b1039927-9e35-455a-b268-c6291252a151)


```python
# 1. æ•°æ®å‡†å¤‡
print("=== STEP1 ===")
trans_df = prepare_transaction_data(df)

# 2. é¢‘ç¹é¡¹é›†æŒ–æ˜
print("\n=== STEP2 ===")
frequent_itemsets, rules = mine_association_rules(trans_df)

# 3. ç»“æœåˆ†æ
print("\n=== STEP3 ===")
if len(rules) > 0:
    # æŒ‰è¯¾ç¨‹è¦æ±‚ä¿å­˜ç»“æœ
    rules.to_csv("association_rules.csv", index=False)
    print("saved to association_rules.csv")

    # æƒ…æ„Ÿç›¸å…³è§„åˆ™åˆ†æï¼ˆè¯¾ç¨‹é¡¹ç›®è¦æ±‚ï¼‰
    sentiment_rules = rules[rules['consequents'].apply(
        lambda x: any('sentiment=' in item for item in x)
    )]
    print("\nRules Top5:")
    print(sentiment_rules[['rule', 'support', 'confidence', 'lift']].head())
else:
    print("Decrease min_supportæˆ–min_threshold")

# 4. å¯è§†åŒ–
print("\n=== STEP4 ===")
plot_rules(rules)
```

ç»“æœ

```python
=== STEP1 ===

=== STEP2 ===

=== STEP3 ===
saved to association_rules.csv

Rules Top5:
                                                 rule   support  confidence  \
8   frozenset({'entity=fbi'}) â†’ frozenset({'sentim...  0.001005    0.831104   
13  frozenset({'category=ENVIRONMENT', 'entity=flo...  0.001052    0.755814   
14  frozenset({'entity=white house', 'category=POL...  0.001187    0.709794   
18  frozenset({'entity=america', 'category=TRAVEL'...  0.001306    0.709890   

        lift  
8   1.853354  
13  1.685459  
14  1.582836  
18  1.726462  

=== STEP4 ===
```
![image](https://github.com/user-attachments/assets/8360e42b-185e-4f5a-8a91-60c9bef462a5)


### Recommand System based on association rules


```python
# -*- coding: utf-8 -*-
"""
åŸºäºå…³è”è§„åˆ™çš„æ–°é—»æ¨èç³»ç»Ÿ
"""

import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
import matplotlib.pyplot as plt

class AssociationRuleRecommender:
    def __init__(self, min_support=0.001, min_confidence=0.5):
        """
        åˆå§‹åŒ–æ¨èå™¨
        :param min_support: æœ€å°æ”¯æŒåº¦
        :param min_confidence: æœ€å°ç½®ä¿¡åº¦
        """
        self.min_support = min_support
        self.min_confidence = min_confidence
        self.rules = None
        self.frequent_itemsets = None

    def fit(self, trans_df):
        """
        è®­ç»ƒå…³è”è§„åˆ™æ¨¡å‹
        :param trans_df: one-hotç¼–ç çš„äº¤æ˜“æ•°æ®
        """
        # æŒ–æ˜é¢‘ç¹é¡¹é›†
        self.frequent_itemsets = apriori(
            trans_df,
            min_support=self.min_support,
            use_colnames=True
        )

        # ç”Ÿæˆå…³è”è§„åˆ™
        self.rules = association_rules(
            self.frequent_itemsets,
            metric="confidence",
            min_threshold=self.min_confidence
        )

        # è¿‡æ»¤æœ‰æ„ä¹‰çš„è§„åˆ™(lift>1)
        self.rules = self.rules[self.rules['lift'] > 1]

        print(f"Generate {len(self.rules)} Association Rules")

    def recommend(self, input_items, top_n=5):
        """
        åŸºäºè¾“å…¥é¡¹ç”Ÿæˆæ¨è
        :param input_items: è¾“å…¥é¡¹åˆ—è¡¨(ç”¨æˆ·å½“å‰æµè§ˆ/ç‚¹å‡»çš„å†…å®¹)
        :param top_n: æ¨èæ•°é‡
        :return: æ¨èç»“æœDataFrame
        """
        if self.rules is None:
            raise ValueError("è¯·å…ˆè®­ç»ƒæ¨¡å‹")

        # åŒ¹é…å‰ä»¶åŒ…å«è¾“å…¥é¡¹çš„è§„åˆ™
        matched_rules = self.rules[
            self.rules['antecedents'].apply(lambda x: x.issubset(set(input_items)))
        ]

        if len(matched_rules) == 0:
            print("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å…³è”è§„åˆ™")
            return pd.DataFrame()

        # æŒ‰æå‡åº¦å’Œç½®ä¿¡åº¦æ’åº
        matched_rules = matched_rules.sort_values(
            ['lift', 'confidence'],
            ascending=False
        )

        # æå–æ¨èç»“æœ
        recommendations = []
        for _, rule in matched_rules.head(top_n).iterrows():
            for item in rule['consequents']:
                recommendations.append({
                    'item': item,
                    'antecedents': ', '.join(rule['antecedents']),
                    'support': rule['support'],
                    'confidence': rule['confidence'],
                    'lift': rule['lift']
                })

        return pd.DataFrame(recommendations).drop_duplicates(subset=['item']).head(top_n)

    def visualize_rules(self, top_n=10):
        """å¯è§†åŒ–å…³è”è§„åˆ™"""
        if self.rules is None:
            raise ValueError("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
    
        plot_data = self.rules.head(top_n).copy()
        
        # è½¬æ¢ antecedents å’Œ consequents ä¸ºå­—ç¬¦ä¸²
        plot_data['rule'] = plot_data.apply(
            lambda row: f"{str(row['antecedents'])} â†’ {str(row['consequents'])}", 
            axis=1)
    
        plt.figure(figsize=(12, 6))
    
        æ”¯æŒåº¦-ç½®ä¿¡åº¦æ•£ç‚¹å›¾
        scatter = plt.scatter(
            plot_data['support'],
            plot_data['confidence'],
            s=plot_data['lift'] * 100,  # ç¡®ä¿ lift å€¼åˆç†ï¼Œå¦åˆ™å¯èƒ½éœ€è¦ç¼©æ”¾
            c=plot_data['lift'],
            alpha=0.6,
            cmap='viridis'
        )
    
        # æ·»åŠ æ ‡ç­¾ï¼Œä½¿ç”¨è½¬æ¢åçš„è§„åˆ™æ–‡æœ¬
        for i, row in plot_data.iterrows():
            plt.annotate(
                row['rule'],
                (row['support'], row['confidence']),
                xytext=(5, 5),
                textcoords='offset points',
                fontsize=8
            )
    
        plt.xlabel('Support')
        plt.ylabel('Confidence')
        plt.title('Association Rules (Color and size for Lift)')
        plt.grid(True, alpha=0.2)
        plt.tight_layout()
        plt.show()

# ç¤ºä¾‹ä½¿ç”¨
def prepare_news_data(df):
    """
    å‡†å¤‡æ–°é—»å…³è”è§„åˆ™æ•°æ®
    :param df: æ–°é—»æ•°æ®é›†(éœ€åŒ…å«category, sentiment_labelç­‰åˆ—)
    :return: one-hotç¼–ç çš„äº¤æ˜“æ•°æ®
    """
    transactions = []

    # ä¸ºæ¯æ¡æ–°é—»åˆ›å»ºç‰¹å¾é›†åˆ
    for _, row in df.iterrows():
        features = []

        # æ·»åŠ ç±»åˆ«
        features.append(f"category={row['category']}")

        # æ·»åŠ æƒ…æ„Ÿæ ‡ç­¾
        features.append(f"sentiment={row['sentiment_label']}")

        # æ·»åŠ å…¥é€‰å®ä½“
        if isinstance(row['entity_sentiments'], dict):
            for entity in row['entity_sentiments'].keys():
                features.append(f"entity={entity[:20]}")  # é™åˆ¶å®ä½“åç§°é•¿åº¦

        transactions.append(features)

    # è½¬æ¢ä¸ºone-hotç¼–ç 
    from mlxtend.preprocessing import TransactionEncoder
    te = TransactionEncoder()
    te_ary = te.fit(transactions).transform(transactions)
    return pd.DataFrame(te_ary, columns=te.columns_)


# å‡†å¤‡å…³è”è§„åˆ™æ•°æ®
trans_df = prepare_news_data(df)

# åˆå§‹åŒ–å¹¶è®­ç»ƒæ¨èå™¨
recommender = AssociationRuleRecommender(min_support=0.001, min_confidence=0.5)
recommender.fit(trans_df)

# ç”Ÿæˆæ¨è
print("\nExample:")
input_items = ['category=ENVIRONMENT']
print(f"\n Input: \n{input_items}")
recommendations = recommender.recommend(input_items)
print(recommendations)

```

ç»“æœ

```python
Generate 77 Association Rules

Example:

 Input: 
['category=ENVIRONMENT']
                 item           antecedents   support  confidence      lift
0  sentiment=negative  category=ENVIRONMENT  0.040403    0.605748  1.350814
```

### News Auto Categorization


```python
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.pipeline import Pipeline

print("Training TF-IDF + SVM model...")

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    df['cleaned_text'], 
    df['category'], 
    test_size=0.2, 
    random_state=42,
    stratify=df['category']
)

# åˆ›å»ºpipeline
svm_pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(max_features=5000)),
    ('classifier', LinearSVC(random_state=42))
])

# è®­ç»ƒæ¨¡å‹
svm_pipeline.fit(X_train, y_train)

# é¢„æµ‹å’Œè¯„ä¼°
y_pred_svm = svm_pipeline.predict(X_test)

# æ‰“å°åˆ†ç±»æŠ¥å‘Š
print("\nClassification Report:")
print(classification_report(y_test, y_pred_svm))

# ä¿å­˜ç»“æœç”¨äºå¯è§†åŒ–
svm_results = {
    'y_true': y_test,
    'y_pred': y_pred_svm,
    'model_name': 'SVM'
}
```

ç»“æœ


```python
Training TF-IDF + SVM model...

Classification Report:
                precision    recall  f1-score   support

           ART       0.00      0.00      0.00        15
          ARTS       0.26      0.16      0.20       173
ARTS & CULTURE       0.31      0.21      0.25       268
  BLACK VOICES       0.44      0.31      0.37       835
      BUSINESS       0.45      0.42      0.43      1029
     CELEBRITY       0.19      0.05      0.07       111
       COLLEGE       0.34      0.30      0.32       184
        COMEDY       0.53      0.44      0.48       928
         CRIME       0.47      0.51      0.49       566
CULTURE & ARTS       0.42      0.29      0.34       213
       DIVORCE       0.78      0.71      0.74       685
     EDUCATION       0.43      0.34      0.38       180
 ENTERTAINMENT       0.56      0.67      0.61      2952
   ENVIRONMENT       0.49      0.50      0.50       945
     EXTREMISM       0.25      0.04      0.06        28
         FIFTY       0.33      0.15      0.20       208
  FOOD & DRINK       0.59      0.73      0.65      1266
     GOOD NEWS       0.26      0.16      0.20       208
         GREEN       0.29      0.15      0.20       409
        HEALTH       0.59      0.48      0.53       754
...
      accuracy                           0.57     39927
     macro avg       0.45      0.38      0.40     39927
  weighted avg       0.54      0.57      0.55     39927

Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...
```


```py
import seaborn as sns
import matplotlib.pyplot as plt

# æ··æ·†çŸ©é˜µå¯è§†åŒ–
plt.figure(figsize=(12, 8))
cm = confusion_matrix(y_test, y_pred_svm)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=svm_pipeline.classes_,
            yticklabels=svm_pipeline.classes_)
plt.title('Confusion Matrix - SVM')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡å¯è§†åŒ–
class_report = classification_report(y_test, y_pred_svm, output_dict=True)
class_df = pd.DataFrame(class_report).transpose()
plt.figure(figsize=(10, 6))
class_df['precision'].iloc[:-3].plot(kind='bar')
plt.title('Precision by Category - SVM')
plt.xlabel('Category')
plt.ylabel('Precision')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```


![image](https://github.com/user-attachments/assets/d2ec6f00-17c4-43c0-95b4-18c8942333d4)



![image](https://github.com/user-attachments/assets/d440b7bc-b4d1-405b-8728-f6f55c48d7f7)

```python
# æµ‹è¯•æ–°é—»åˆ†ç±»
def classify_news(text, pipeline):
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æ–°é—»è¿›è¡Œåˆ†ç±»
    
    å‚æ•°:
        text (str): æ–°é—»æ–‡æœ¬
        pipeline: è®­ç»ƒå¥½çš„æ¨¡å‹pipeline
    
    è¿”å›:
        dict: åŒ…å«åˆ†ç±»ç»“æœå’Œé¢„æµ‹æ¦‚ç‡çš„å­—å…¸
    """
    # é¢„æµ‹ç±»åˆ«
    predicted_category = pipeline.predict([text])[0]
    
    # è·å–å†³ç­–å‡½æ•°å€¼ï¼ˆå¯ä»¥ç”¨æ¥è¡¨ç¤ºé¢„æµ‹çš„ç¡®ä¿¡åº¦ï¼‰
    decision_scores = pipeline.decision_function([text])[0]
    
    # è·å–æ‰€æœ‰ç±»åˆ«æ ‡ç­¾
    categories = pipeline.classes_
    
    # å°†å†³ç­–åˆ†æ•°è½¬æ¢ä¸ºç›¸å¯¹ç¡®ä¿¡åº¦ï¼ˆé€šè¿‡softmaxï¼‰
    confidence_scores = np.exp(decision_scores) / np.sum(np.exp(decision_scores))
    
    # åˆ›å»ºç±»åˆ«-ç¡®ä¿¡åº¦å¯¹åº”å…³ç³»
    category_confidence = dict(zip(categories, confidence_scores))
    
    # æŒ‰ç¡®ä¿¡åº¦æ’åº
    sorted_predictions = sorted(
        category_confidence.items(), 
        key=lambda x: x[1], 
        reverse=True
    )
    
    return {
        'predicted_category': predicted_category,
        'confidence_scores': sorted_predictions
    }

# æµ‹è¯•æ ·ä¾‹
sample_news = """Trump and his allies say short-term economic pain, through higher prices on consumer goods, 
                is worth the glory that tariffs will bring."""

# è¿›è¡Œé¢„æµ‹
result = classify_news(sample_news, svm_pipeline)

# æ‰“å°ç»“æœ
print("Text:")
print("-" * 80)
print(sample_news)
print("-" * 80)

print("-" * 80)
print("\nResult:")
print(f"Predict Label: \n#{result['predicted_category']}\n")
print("-" * 80)
print("\nConfidence Mat:")
for category, confidence in result['confidence_scores']:
    print(f"{category}: {confidence:.4f}")
```



```python
Text:
--------------------------------------------------------------------------------
Trump and his allies say short-term economic pain, through higher prices on consumer goods, 
                is worth the glory that tariffs will bring.
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------

Result:
Predict Label: 
#POLITICS

--------------------------------------------------------------------------------

Confidence Mat:
POLITICS: 0.0532
STYLE: 0.0358
GREEN: 0.0314
BUSINESS: 0.0305
STYLE & BEAUTY: 0.0305
COLLEGE: 0.0290
BLACK VOICES: 0.0289
MONEY: 0.0278
FOOD & DRINK: 0.0274
PARENTS: 0.0269
U.S. NEWS: 0.0264
...
FIFTY: 0.0117
WEDDINGS: 0.0115
GOOD NEWS: 0.0112
WORLDPOST: 0.0083
Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...
```


